# ğŸ”„ Working Progress - AI Log Analyzer

**Projekt:** AI Log Analyzer - Phase 5B (Production Readiness)  
**PoslednÃ­ update:** 2025-12-19 15:00 UTC  
**Status:** âœ… Peak detection HOTOVO! | ğŸ”„ Verifikace probÃ­hÃ¡

---

## ğŸ“‹ CURRENT TASKS (Priority Order)

### âœ… COMPLETED TODAY (2025-12-19)

**14:00-14:40 UTC - Peak Detection Implementace & Test**
- âœ… VytvoÅ™ena `detect_and_skip_peaks()` funkce (Å™Ã¡dky 89-153 v ingest_from_log.py)
- âœ… Baseline normalization: reference < 5 â†’ use 5
- âœ… Batch ingest 9 souborÅ¯: 6,678 parsed patterns
- âœ… Peak detection funguje: 79 peaks skipnuto z celkem
- âœ… DB contains: 3,393 rows (po UPSERT agregaci)
- âœ… Verifikace: KritickÃ© peaks skipnuty (2884-2899 v pcb-ch-sit)

**VÃ½sledky (2025-12-19 14:40 UTC):**
```
Parsed:   6,678 patterns  
Skipped:  79 peaks (1.2%)
Inserted: 6,599 rows
DB Final: 3,393 rows (UPSERT redukce duplicit)

Peak Detection Ratio (Top 5):
- Thu 07:00 pcb-ch-sit: 46.5Ã— SKIP âœ…
- Fri 07:00 pcb-ch-sit: 46.8Ã— SKIP âœ…  
- Sat 07:00 pcb-ch-sit: 46.7Ã— SKIP âœ…
- Tue 07:00 pcb-ch-sit: 46.7Ã— SKIP âœ…
- Mon 15:30 pcb-dev:    150Ã—  SKIP âœ…
```

---

## ğŸ‰ SESSION 2025-12-19 (14:00-14:40 UTC) - PEAK DETECTION IMPLEMENTOVÃNA A FUNGUJE!

### âœ… VÃSLEDKY:
- **Peak detection funguje!** 79 peaks skipnuto z 6,678 patterns
- **DB obsahuje:** 3,393 rows (normÃ¡lnÃ­ hodnoty po UPSERT agregaci)
- **VÅ¡echny kritickÃ© peaks skipnuty:**
  - Thu 07:00 pcb-ch-sit: 2884.0 (46.5Ã—) âœ…
  - Fri 07:00 pcb-ch-sit: 2899.0 (46.8Ã—) âœ…
  - Sat 07:00 pcb-ch-sit: 2895.0 (46.7Ã—) âœ…
  - Tue 07:00 pcb-ch-sit: 2898.0 (46.7Ã—) âœ…

### ğŸ“ CO BYLO UDÄšLÃNO:

**14:00 - AnalÃ½za problÃ©mu:**
- ZjiÅ¡tÄ›no: `detect_and_skip_peaks()` funkce NEEXISTOVALA v aktivnÃ­m kÃ³du
- PÅ¯vodnÃ­ `ingest_from_log.py` (Å™Ã¡dek 90) mÄ›l starou verzi BEZ peak detection
- Funkce byla jen v dokumentaci/working_progress, nikdy implementovÃ¡na

**14:15 - Implementace:**
1. âœ… VytvoÅ™il `detect_and_skip_peaks()` funkci (Å™Ã¡dek 89-153)
   - HledÃ¡ 3 okna PÅ˜ED (same day: -15min, -30min, -45min)
   - HledÃ¡ 3 dny zpÄ›t (same time: day-1, day-2, day-3)
   - PouÅ¾Ã­vÃ¡ PARSED DATA (ne DB!) - klÃ­ÄovÃ© pro sprÃ¡vnou funkci
   - Baseline normalization: reference < 5 â†’ use 5
   - Threshold: 15Ã— (normal), 50Ã— (kdyÅ¾ reference < 10)

2. âœ… PÅ™idal volÃ¡nÃ­ v `insert_statistics_to_db()` (Å™Ã¡dek 213-221)
   ```python
   is_peak, ratio, reference = detect_and_skip_peaks(...)
   if is_peak:
       # Log to /tmp/peaks_skipped.log
       continue  # SKIP this row
   ```

**14:25 - Test & Verifikace:**
- Single file test (04_05): 13 peaks skipnuto, 933 insertÅ¯ âœ…
- Batch ingest (9 files): 79 peaks skipnuto celkem âœ…
- DB rows: 3,393 (down from 6,678 parsed patterns) âœ…

### ğŸ“Š BATCH INGEST STATISTICS:

| Soubor | Parsed | Inserted | Skipped |
|--------|--------|----------|---------|
| 2025-12-01 | 186 | 182 | 4 |
| 2025-12-02_03 | 712 | 703 | 9 |
| 2025-12-04_05 | 946 | 933 | 13 |
| 2025-12-06_07 | 843 | 838 | 5 |
| 2025-12-08_09 | 968 | 960 | 8 |
| 2025-12-10_11 | 947 | 933 | 14 |
| 2025-12-12_13 | 930 | 919 | 11 |
| 2025-12-14_15 | 896 | 886 | 10 |
| 2025-12-16 | 250 | 245 | 5 |
| **TOTAL** | **6,678** | **6,599** | **79** |

**Final DB:** 3,393 rows (UPSERT aggregation reduces duplicates)

### ğŸ“Š FINÃLNÃ VERIFIKACE:

**Top hodnoty v DB (po peak detection):**
- Max value: **41,635** (Mon 15:30 pcb-dev-01-app)
- Avg value: **225.3**
- Total rows: **3,393**

**AnalÃ½za max hodnoty 41,635:**
- âš ï¸ Hodnota z **2025-12-01** (prvnÃ­ den) - NEBYLA skipnuta
- â“ DÅ¯vod: PrvnÃ­ soubor nemÃ¡ historical references (day-1, day-2, day-3 neexistujÃ­)
- âœ… StejnÃ¡ hodnota v dalÅ¡Ã­ch dnech (08-08: 8352, 12-15: 9209) **byla skipnuta** âœ…
- âœ… KritickÃ© peaks (2884, 2885, 2895, 2898) **skipnuty** âœ…

**ZÃ¡vÄ›r:**
- Peak detection **FUNGUJE** kdyÅ¾ mÃ¡ data pro comparison
- PrvnÃ­ den (2025-12-01) mÃ¡ vysokÃ© hodnoty protoÅ¾e nemÃ¡ references
- **Å˜eÅ¡enÃ­:** NahrÃ¡t data postupnÄ› od nejstarÅ¡Ã­ch, nebo ignorovat prvnÃ­ den

**SkipnutÃ© peaks log:** `/tmp/peaks_skipped.log` (79 peaks)

---

## ğŸ¯ NEXT STEPS (Priority Order - 2025-12-19)

**14:00 UTC** - ZaÄÃ¡tek session
- CÃ­l: Testovat baseline normalizaci
- Data v .txt mÄ›ly Thu 06:00 (bez offset z ES)
- Ingest aplikoval +1h offset â†’ DB mÄ›l Thu 07:00 âŒ

**14:30 UTC** - ZJIÅ TÄšNÃ #1: TIMEZONE OFFSET
- ProblÃ©m: .txt majÃ­ ES Äasy (06:00), ingest dÄ›lÃ¡ +1h â†’ DB 07:00
- Å˜eÅ¡enÃ­: Opravit collect aby dÄ›lal +1h PÅ˜I SBÄšRU (ne v ingest)
- Opravit .txt soubory (+1h) a smazat offset z ingest

**15:00 UTC** - ZJIÅ TÄšNÃ #2: DOUBLE OFFSET
- Opravil jsem collect_peak_detailed.py: +1h CET konverze âœ…
- Opravil jsem vÅ¡echny .txt soubory: +1h posun âœ… (9 souborÅ¯)
- ALE: Ingest STÃLE mÄ›l +1h offset v kÃ³du! âŒ
- Zjistil jsem: Windows line endings (CRLF) zabrÃ¡nily editaci!

**15:15 UTC** - OPRAVA LINE ENDINGS + OFFSET REMOVAL
- âœ… KonvertovÃ¡n CRLF â†’ LF
- âœ… OdstranÄ›n +1h offset z ingest_from_log.py
- âœ… Syntax OK
- âœ… Obnoveny opravenÃ© .txt soubory (s +1h posounem)

**15:30 UTC** - RE-INGEST TEST
- Clear DB âœ…
- Ingest /tmp/peak_fixed_2025_12_04_05.txt
- **VÃSLEDEK: PEAKS STÃLE V DB!** âŒ
  - Thu 07:00 pcb-ch-sit-01-app: 2884.0 (mÄ›lo by bÃ½t SKIPNUTO!)
  - Fri 07:00 pcb-ch-sit-01-app: 2885.0 (mÄ›lo by bÃ½t SKIPNUTO!)

- Kontrola /tmp/peaks_skipped.log: **NEEXISTUJE!** ğŸ”´
- To znamenÃ¡: Ingest skonÄil s ERROR nebo peak detekce nefunguje

---

## ğŸ” AKTUÃLNÃ STAV KÃ“DU

### collect_peak_detailed.py (Å˜Ã¡dka 149-155)
```python
win_start_cet = win_start + timedelta(hours=1)  # âœ… CET konverze
day_of_week = win_start_cet.weekday()
hour_of_day = win_start_cet.hour
```
**Status:** âœ… SprÃ¡vnÄ› - aplikuje +1h

### ingest_from_log.py (Å˜Ã¡dka 71-77)
```python
# âœ… NO TIMEZONE OFFSET - .txt already has correct times
day_of_week = day_map.get(day_name, 0)

# Calculate quarter hour (0, 15, 30, 45)
quarter_hour = (minute // 15) % 4

key = (day_of_week, hour, quarter_hour, namespace)
```
**Status:** âœ… Bez offsetu - bere `hour` pÅ™Ã­mo ze .txt

### .txt soubory (9 souborÅ¯)
- peak_fixed_2025_12_01.txt âœ… +1h posun
- peak_fixed_2025_12_02_03.txt âœ… +1h posun
- peak_fixed_2025_12_04_05.txt âœ… +1h posun (Thu 06:00 â†’ Thu 07:00)
- peak_fixed_2025_12_06_07.txt âœ… +1h posun
- peak_fixed_2025_12_08_09.txt âœ… +1h posun
- peak_fixed_2025_12_10_11.txt âœ… +1h posun
- peak_fixed_2025_12_12_13.txt âœ… +1h posun
- peak_fixed_2025_12_14_15.txt âœ… +1h posun
- peak_fixed_2025_12_16.txt âœ… +1h posun

**Status:** âœ… VÅ¡echny opraveny

---

## ğŸš¨ NOVÃ PROBLÃ‰M - PEAKS NEJSOU DETEKOVANÃ‰

### DB State (po re-ingest):
```
Total rows: 946 (mÄ›lo by bÃ½t < 946, protoÅ¾e peaks by mÄ›ly bÃ½t skipnuty)

TOP peaks v DB:
  Thu 07:00 pcb-ch-sit-01-app: 2884.0 âŒ PEAK! (mÄ›lo by bÃ½t SKIPNUTO)
  Fri 07:00 pcb-ch-sit-01-app: 2885.0 âŒ PEAK! (mÄ›lo by bÃ½t SKIPNUTO)
  
Baseline hodnoty: 324 (OK - ty by mÄ›ly bÃ½t v DB)
```

### HypotÃ©zy:
1. â“ Detekce peaks nefunguje (detect_and_skip_peaks vracÃ­ False)
2. â“ Peak detection je vypnutÃ½ nebo skipped
3. â“ Ingest konÄÃ­ s error pÅ™ed peak detection
4. â“ Logs nejsou vytvÃ¡Å™eny - znamenÃ¡ crash v insert_statistics_to_db

---

## âœ… CO JE HOTOVO

1. âœ… Opravit collect_peak_detailed.py - +1h CET conversion
2. âœ… Opravit ingest_from_log.py - odebrat +1h offset
3. âœ… Opravit vÅ¡echny .txt soubory - +1h posun (9 souborÅ¯)
4. âœ… OvÄ›Å™it line endings (CRLF â†’ LF)
5. âœ… OvÄ›Å™it syntax vÅ¡ech scriptÅ¯

## âŒ CO ZBÃVÃ - PRIORITY ORDER

1. [ ] **URGENT:** DEBUG print statements pÅ™idÃ¡ny - bÄ›Å¾Ã­ test ingest
   - PÅ™idÃ¡ny LOOP a DEBUG outputs v ingest_from_log.py
   - ÄŒekÃ¡ se na vÃ½sledek...

2. [ ] Zjistit proÄ peak detection nefunguje:
   - NejspÃ­Å¡ dÅ¯vod: MÃ¡me jen 2 dny dat (Thu-Fri)
   - Pro Thu se nemohou zÃ­skat refs_days (den-1, den-2, den-3 neexistujÃ­)
   - DÄ›lÃ¡ se return `(False, None, None)` â†’ nedetekuje se jako peak

3. [ ] MoÅ¾nÃ© Å™eÅ¡enÃ­:
   - PouÅ¾Ã­t jen refs_windows (3 okna pÅ™ed) mÃ­sto poÅ¾adavku refs_days
   - Nebo: SnÃ­Å¾it threshold kdyÅ¾ chybÃ­ historical data
   - Nebo: NahrÃ¡t vÅ¡ech 9 .txt souborÅ¯ najednou (pak bude vÃ­c dat pro refs_days)

4. [ ] FINÃLNÃ KROKY:
   - [ ] Clear DB
   - [ ] NahrÃ¡t vÅ¡ech 9 .txt souborÅ¯ do DB
   - [ ] OvÄ›Å™it Å¾e peaks jsou skipnuty
   - [ ] Kontrola top values: max < 1000

---

## ğŸ¯ DALÅ Ã SESSION - Priority

**NEJDÅ®LEÅ½ITÄšJÅ Ã:**
1. Zjistit proÄ peak detection vracÃ­ False
2. Opravit logiku - umoÅ¾nit detekci i bez historical data
3. NahrÃ¡t vÅ¡ech 9 souborÅ¯
4. FinÃ¡lnÃ­ test

## ï¿½ CRITICAL ISSUES FOUND - 2025-12-19 10:15 UTC

### PROBLÃ‰M 1: ChybÄ›jÃ­cÃ­ referenÄnÃ­ okna (1 z 3)

**Situace:**
```
Target: Fri 08:00 pcb-ch-sit-01-app = 2.0

ReferenÄnÃ­ okna PÅ˜ED (mÄ›lo by 3):
  -15min (07:45): (4, 7, 3) = NEEXISTUJE âŒ
  -30min (07:30): (4, 7, 2) = 62.0 âœ…
  -45min (07:15): (4, 7, 1) = NEEXISTUJE âŒ

VÃ½sledek: refs_windows = [62.0] - JEN 1 Z 3!
```

**DÅ¯vod:** Nejsou vÅ¡echna 15-minutovÃ¡ okna v datech

**DÅ¯sledek:**
- Reference = 62.0 (mÃ­sto prÅ¯mÄ›ru 3 oken)
- Ratio = 2.0 / 62.0 = 0.032 < 15 â†’ NEDETEKUJE SE JAKO PEAK
- âœ… SprÃ¡vnÄ› (2.0 nenÃ­ peak), ALE za Å¡patnÃ½ch dÅ¯vodÅ¯

**Å˜EÅ ENÃ:**
- Pokud mÃ¡me < 2 okna ze 3, nedetekuj peak z tÄ›chto dat
- Nebo: Aplikuj vyÅ¡Å¡Ã­ threshold (napÅ™. 50Ã— mÃ­sto 15Ã—) pokud chybÃ­ > 1 okna

---

### PROBLÃ‰M 2: MalÃ½ baseline â†’ faleÅ¡nÃ© peaks

**Situace:**
```
Baseline = 2.0 (malÃ¡ hodnota)
Reference okno = 62.0

Ratio = 62.0 / 2.0 = 31Ã— (Peak! - vÅ¯Äi 15Ã—) âŒ Å PATNÄš!
```

**DÅ¯sledek:** TÃ©mÄ›Å™ jakÃ©koli zvÃ½Å¡enÃ­ z malÃ©ho baseline se povaÅ¾uje za peak! âŒ

**PÅ™Ã­klad z reÃ¡lnÃ½ch dat:**
```
Sekvence: 2, 62, 2 (Thu 07:45, 08:00, 08:15)
â†’ 62 by se mÄ›lo ignorovat jako noise, ne detekovat jako peak
â†’ Reference = 2 â†’ Ratio 62/2 = 31Ã— â†’ FALSE POSITIVE âŒ
```

**Å˜EÅ ENÃ - BASELINE NORMALIZATION (SCHVÃLENO):**

Pokud je reference < 5, **nahraÄ na 5** pÅ™i vÃ½poÄtu ratia!

```python
# KLÃÄŒ: Normalizace malÃ½ch baseline hodnot
avg_windows = sum(refs_windows) / len(refs_windows) if refs_windows else None
avg_days = sum(refs_days) / len(refs_days) if refs_days else None

# VypoÄti reference
if avg_windows is not None and avg_days is not None:
    reference = (avg_windows + avg_days) / 2.0
elif avg_windows is not None:
    reference = avg_windows
elif avg_days is not None:
    reference = avg_days
else:
    return (False, None, None, {...})

# âœ… NORMALIZACE: Pokud je reference < 5, pouÅ¾ij 5
# DÅ¯vod: MalÃ© baseline = pÅ™irozenÃ¡ variabilita, ne anomÃ¡lie
if reference < 5:
    reference = 5
```

**PÅ™Ã­klady:**

1. **Sekvence: 2, 62, 2 (normÃ¡lnÃ­ variabilita)**
   ```
   refs_windows = [62.0]
   avg_windows = 62 â†’ keep 62 (â‰¥ 5)
   reference = 62
   Ratio = 2 / 62 = 0.032Ã— â†’ NENÃ peak âœ…
   ```

2. **Sekvence: 2, 2, 2, 80 (skuteÄnÃ½ peak!)**
   ```
   refs_windows = [2.0] â†’ keep, ale:
   avg_windows = 2 â†’ normalize na 5 (< 5)
   reference = 5
   Ratio = 80 / 5 = 16Ã— â†’ PEAK âœ… SprÃ¡vnÄ›!
   ```

3. **Sekvence: 1, 1, 100 (ÄistÃ½ peak)**
   ```
   refs_windows = [1.0] â†’ avg = 1 â†’ normalize na 5
   reference = 5
   Ratio = 100 / 5 = 20Ã— â†’ PEAK âœ…
   ```

4. **Sekvence: 1, 1, 5 (normÃ¡lnÃ­ variabilita s malÃ½m baseline)**
   ```
   refs_windows = [1.0] â†’ avg = 1 â†’ normalize na 5
   reference = 5
   Ratio = 5 / 5 = 1.0Ã— â†’ NENÃ peak âœ…
   ```

**VÃ½hody:**
- âœ… ZbavÃ­me se faleÅ¡nÃ½ch peaks z malÃ©ho baseline
- âœ… ZachovÃ¡me detekci skuteÄnÃ½ch anomÃ¡liÃ­ (>15Ã— i u malÃ½ch baseline)
- âœ… DoÄasnÃ© Å™eÅ¡enÃ­ - funguje dokud nemÃ¡me kompletnÃ­ 6 vzorkÅ¯
- âœ… ElegantnÃ­ - jen jeden Å™Ã¡dek kÃ³du!
- âœ… BezpeÄnÃ© - nemÄ›nÃ­me threshold, jen normalizujeme vstup

---

## ğŸ”§ IMPLEMENTACE - 2025-12-19 10:25 UTC

### âœ… DOKONÄŒENO:

1. âœ… **Baseline Normalization Loop implementovÃ¡n** v `detect_and_skip_peaks()`
   - Pokud `reference < 5`, nahraÄ na `5`
   - PÅ™idÃ¡n komentÃ¡Å™ s pÅ™Ã­klady
   - ZjednoduÅ¡ena Peak decision logika (odstranÄ›ny stare insufficient_windows podmÃ­nky)

2. âœ… **Syntax verifikovÃ¡n** - `python3 -m py_compile` OK

3. âœ… **Dokumentace aktualizovÃ¡na** s pÅ™Ã­klady

### ğŸ“ KÃ“D:

```python
# âœ… BASELINE NORMALIZATION: If reference < 5, use 5
if reference < 5:
    reference = 5
```

**Efekt v Peak detection:**
- StarÃ©: `Ratio = 62 / 2 = 31Ã—` â†’ FALSE PEAK âŒ
- NovÃ©: `Ratio = 62 / 5 = 12.4Ã—` â†’ NOT A PEAK âœ…

---

## ğŸ§ª NEXT: TEST INGESTION

**PÅ™Ã­Å¡tÃ­ kroky:**
1. Smazat DB: `python scripts/clear_peak_db.py`
2. Ingestionovat test data: `python scripts/ingest_from_log.py --input /tmp/peak_fixed_2025_12_04_05.txt`
3. OvÄ›Å™it: `python scripts/check_db_data.py`
4. Kontrolovat Å¾e:
   - âœ… Fri 08:00 pcb-ch-sit: **2.0** nebo **max 10** (baseline + normalization)
   - âŒ NE 2885 (mÄ›lo by bÃ½t skipnuto!)
   - âœ… Fri 07:30 pcb-ch-sit: 62.0 (normal pattern)

---

## ğŸ“Œ DOKUMENTACE

---

## ï¿½ğŸ“ SESSION SUMMARY - 2025-12-18 16:20 UTC - ROOT CAUSE FOUND!

### ğŸ”´ ROOT CAUSE NALEZEN!

**DETAILNÃ ANALÃZA CODE:**

ProblÃ©m se nachÃ¡zÃ­ v `detect_and_skip_peaks()` - funkce hledÃ¡ referenÄnÃ­ okna v **DB**, ale data nejsou v DB kdyÅ¾ se provÃ¡dÃ­ ingestion!

**CIRCULAR DEPENDENCY:**

```
Ingestion proces:
1. Parsujeme data ze souboru (946 Å™Ã¡dkÅ¯ Thu+Fri)
   â””â”€ statistics_dict = {(day, hour, qtr, ns): {mean, stddev, samples}}

2. Pro KAÅ½DÃ Å™Ã¡dek detekujeme peaks:
   â”œâ”€ detect_and_skip_peaks(cur, day, hour, qtr, ns, mean)
   â”‚
   â””â”€ detect_and_skip_peaks() queÅ™uje v DB:
      â”œâ”€ SELECT FROM peak_statistics WHERE day_of_week IN (day-1, day-2, day-3)
      â”‚  â† HledÃ¡ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ° data z minulÃ½ch dnÃ­
      â”‚
      â””â”€ PROBLÃ‰M: DB je PRÃZDNÃ!
         â”œâ”€ PÅ™i prvnÃ­m ingestionu Thu+Fri: DB nemÃ¡ data z Wed, Tue, Mon
         â”œâ”€ refs_days = [] (prÃ¡zdnÃ©!)
         â”œâ”€ reference = None nebo jen avg_windows
         â”œâ”€ ratio se nepoÄÃ­tÃ¡ sprÃ¡vnÄ›
         â””â”€ âŒ PEAKS SE NEDETEKUJÃ!
```

**DÅ®SLEDEK: VÅ¡ech 28 peaks jde do DB bez detekce!**

---

### âœ… OBJASNÄšNÃ‰ CHOVÃNÃ - ProÄ logika selhÃ¡vÃ¡:

| ÄŒÃ¡st | Co se dÄ›je | Status |
|------|-----------|--------|
| **parse_peak_statistics_from_log()** | âœ… Data se Ätou sprÃ¡vnÄ› | âœ… OK |
| **detect_and_skip_peaks(cur, ...)** | ğŸ”´ HledÃ¡ v **PRÃZDNÃ‰ DB** | âŒ FAIL |
| **Peak detection algorithm** | ğŸ”´ reference = None | âŒ SKIP NEPROVÃDÃ |
| **Insertion to DB** | âœ… VÅ¡echna data se vloÅ¾Ã­ | âœ… (Å PATNÄš!) |
| **Result** | ğŸ”´ 28 peaks v DB | âŒ NESPRÃVNÃ‰ |

---

### ğŸ¯ Å˜EÅ ENÃ: Peak Detection musÃ­ hledat v PARSOVANÃCH DATECH!

**AktuÃ¡lnÃ­ Å¡patnÃ¡ logika:**
```python
def detect_and_skip_peaks(cur, day_of_week, hour_of_day, quarter_hour, namespace, mean_val):
    # ... Query DB pro references ...
    cur.execute(sql_days, (namespace, hour_of_day, quarter_hour, day_minus_1, day_minus_2, day_minus_3))
    refs_days = [row[0] for row in cur.fetchall()]  # â† DB je PRÃZDNÃ!
```

**SprÃ¡vnÃ¡ logika:**
```python
def detect_and_skip_peaks_from_parsed_data(
    day_of_week, hour_of_day, quarter_hour, namespace, mean_val,
    all_parsed_stats  # â† Use PARSED DATA, not DB!
):
    # STEP 1: Hledej 3 okna PÅ˜ED v parsed data
    refs_windows = []
    for i in range(1, 4):
        prev_data = all_parsed_stats.get((day_of_week, hour-i*15, qtr, namespace))
        if prev_data:
            refs_windows.append(prev_data['mean'])
    
    # STEP 2: Hledej 3 dny zpÄ›t v PARSED DATA
    refs_days = []
    for d in [-1, -2, -3]:
        prev_day = (day_of_week + d) % 7
        prev_data = all_parsed_stats.get((prev_day, hour_of_day, quarter_hour, namespace))
        if prev_data:
            refs_days.append(prev_data['mean'])
    
    # STEP 3: NormÃ¡lnÃ­ algoritmus pro vÃ½poÄet reference a detekci
    # ...
```

**VÃHODA:** HledÃ¡ v parsovanÃ½ch datech, kterÃ¡ EXISTUJÃ!

---

## âœ… NEXT STEPS (PRIORITY):

1. âœ… **ROOT CAUSE IDENTIFIED** - Peak detection hledÃ¡ v neexistujÃ­cÃ­ch DB datech
2. ğŸ”§ **FIX KODU** - Implementovat `detect_and_skip_peaks_from_parsed_data()` nebo:
   - Upravit existujÃ­cÃ­ `detect_and_skip_peaks()` aby hledal v parsed stats
   - PÅ™edat vÅ¡echny parsed stats do insert funkce
3. ğŸ§ª **TEST** - Re-run ingest s opravou
4. âœ… **VERIFY** - OvÄ›Å™it Å¾e peaks NEJSOU v DB

---

### ğŸ“Œ DETAILED CODE ANALYSIS - UloÅ¾eno v:
- `CODE_ANALYSIS_20251218.md` - KompletnÃ­ rozbor s Å™Ã¡dkovÃ½mi ÄÃ­sly a pÅ™Ã­klady
4. âŒ ProblematickÃ© peaks (07:00 ~2890) jsou V DB - MÄšLY bÃ½t skipnuty!

**SPRÃVNÃ‰ Å˜EÅ ENÃ (SCHVÃLENO UÅ½IVATELEM):**
- âœ… KombinovanÃ¡ logika JE SPRÃVNÃ (2 SELECTy jsou OK, rychlost nevadÃ­)
- âœ… Peak detection: avg_windows (3 okna pÅ™ed) + avg_days (3 dny) / 2
- âœ… Threshold: 15Ã— â†’ SKIP
- âœ… Tato logika sprÃ¡vnÄ› detekuje REKURENTNÃ peaks (07:00 kaÅ¾dÃ½ den)

**IMPLEMENTACE DOKONÄŒENA (15:10 UTC):**
1. âœ… ZÃ¡lohovÃ¡n ingest_from_log.py â†’ .backup_20251218_1505
2. âœ… PÅ™epsÃ¡na funkce detect_and_skip_peaks() - ÄistÃ¡ logika:
   - KombinovanÃ© reference (3 okna + 3 dny)
   - SpeciÃ¡lnÃ­ handling pro hodnoty < 10 (threshold 50Ã—)
   - NIKDY neskipovat hodnoty < 10 (baseline)
3. âœ… PÅ™epsÃ¡n insert blok - pouÅ¾Ã­vÃ¡ novÃ½ tuple return
4. âœ… DEBUG vÃ½stupy pro pcb-ch-sit 05:00-09:00

**TEST VÃSLEDKY:**
- TEST #1 (15:10 UTC): âŒ 946 rows, 0 skipnutÃ½ch - DEBUG nefungoval (syntax error)
- TEST #2 (15:12 UTC): âœ… 946 rows inserted - DOKONÄŒENO
- Log: /tmp/final_test.log (finished 15:12 UTC)

### ğŸ¯ DB FIX V PROCESU

**DokonÄeno:**
1. âœ… NaÄten kontext + stav z pÅ™edchozÃ­ session (13:05 UTC)
2. âœ… FIX peak detection implementovÃ¡n - kombinovanÃ¡ logika:
   - Reference = (avg 3 oken pÅ™ed + avg 3 dny stejnÃ½ Äas) / 2
   - SprÃ¡vnÄ› detekuje peaks v Äase I peaks opakujÃ­cÃ­ se kaÅ¾dÃ½ den
3. âœ… DELETE vÅ¡ech dat z DB: `clear_peak_db.py` â†’ 0 rows (13:10 UTC)
4. â³ Batch re-ingest 9 souborÅ¯ s OPRAVENOU logikou:
   - âœ… File 1/9: 2025-12-01 â†’ kompletnÃ­
   - âœ… File 2/9: 2025-12-02_03 â†’ kompletnÃ­
   - âœ… File 3/9: 2025-12-04_05 â†’ kompletnÃ­
   - âœ… File 5/9: 2025-12-08_09 â†’ kompletnÃ­ (poÅ™adÃ­ zmÄ›nÄ›no - batch issue)
   - âœ… File 6/9: 2025-12-10_11 â†’ kompletnÃ­
   - â³ File 4/9: 2025-12-06_07 â†’ PRÃVÄš PROBÃHÃ (14:10 UTC)
   - â³ File 7/9: 2025-12-12_13 â†’ ÄekÃ¡
   - â³ File 8/9: 2025-12-14_15 â†’ ÄekÃ¡
   - â³ File 9/9: 2025-12-16 â†’ ÄekÃ¡
   
   **Current DB State:** 2530 rows (5 souborÅ¯ z 9)

**âš ï¸  PROBLÃ‰M NALEZEN - 14:10 UTC:**
- KombinovanÃ¡ peak logika (2 SELECTy v loopu) je PÅ˜ÃLIÅ  POMALÃ
- KaÅ¾dÃ½ insert dÄ›lÃ¡ 2Ã— DB SELECT â†’ timeout/freeze
- Soubor 06_07 se zasekÃ¡vÃ¡ na ~843 insertech
  
**ğŸ”§ Å˜EÅ ENÃ - 14:20 UTC:**
- âœ… Git revert k pÅ¯vodnÃ­ jednoduchÃ© logice (jen previous days)
- âœ… DELETE DB â†’ 2530 rows deleted â†’ 0 remaining  
- â³ Batch re-ingest se starou logikou - 14:25 UTC

**Status 14:30 UTC:**
- âœ… Git revert zpÅ¯sobil ztrÃ¡tu `load_dotenv()` - FIX pÅ™idÃ¡n pomocÃ­ sed
- âœ… Batch V2 spuÅ¡tÄ›n s opravenÃ½m kÃ³dem (14:28 UTC)
- â³ ProbÃ­hÃ¡ ingest vÅ¡ech 9 souborÅ¯ se STAROU jednoduchou logikou
- Expected: ~3300-3400 rows, nÄ›kterÃ© peaks nebudou skipnuty (opakujÃ­cÃ­ se dennÄ›)

**DB State (pÅ™ed fixem):**
- 3399 rows (CONTAMINATED - mix starÃ½ch smoothed + novÃ½ch skipped values)
- 10 namespaces (pca-*, pcb-*, pcb-ch-*)
- Last update: 2025-12-17 15:41:14 UTC

**Problem potvrzenÃ½ (pÅ™ed fixem):**
- 5.12 Sat 20:00 pcb-dev: 998.0 (mÄ›lo bÃ½t skipnuto z 1573) âŒ BROKEN
- NÄ›kterÃ© peaks jsou ÄÃ¡steÄnÄ› redukovÃ¡ny ale NEJSOU sprÃ¡vnÄ› skipnuty

**NynÃ­ probÃ­hÃ¡:** Clean re-ingest vÅ¡ech 9 souborÅ¯ - bez UPSERT agregace

### ğŸ“‹ TODO LIST - PRIORITY ORDER

```
PHASE: DB FIX (DELETE + RE-INGEST)

[1] âœ… DELETE all peak_statistics data - 2025-12-18 11:35 UTC
    Command: python scripts/clear_peak_db.py
    Result: 3399 rows deleted â†’ 0 rows remaining
    Note: TRUNCATE selhalo (DDL LDAP issue), DELETE funguje âœ…
    
[2] âœ… RE-INGEST vÅ¡ech 9 batchÅ¯ - DOKONÄŒENO - 2025-12-18 11:40-12:35 UTC
    Status: âœ… 9/9 souborÅ¯ zpracovÃ¡no
      âœ… File 1/9: 2025-12-01 â†’ 186 rows, 0 peaks (baseline)
      âœ… File 2/9: 2025-12-02_03 â†’ 712 rows, 0 peaks
      âœ… File 3/9: 2025-12-04_05 â†’ 933 rows, 13 peaks SKIPNUTO (5 EXTREME >100Ã—) âœ…
      âœ… File 4/9: 2025-12-06_07 â†’ 842 rows, 1 peak skipnut
      âœ… File 5/9: 2025-12-08_09 â†’ 938 rows, 30 peaks SKIPNUTO (6 EXTREME, 2 SEVERE) âœ…
      âœ… Files 6-9: DokonÄeno
    Result: 3343 Å™Ã¡dkÅ¯ v DB
    Command:
      for f in /tmp/peak_fixed_2025_12_*.txt; do 
        python scripts/ingest_from_log.py --input "$f"
      done > /tmp/batch_ingest.log 2>&1 &
    
    âœ… Peak detection FUNGUJE sprÃ¡vnÄ›!
    Commands: 
      cd /home/jvsete/git/sas/ai-log-analyzer
      source .venv/bin/activate
      for file in /tmp/peak_fixed_*.txt; do 
        echo "Processing: $file"
        python scripts/ingest_from_log.py --input "$file"
      done
    Expected: ~3300 rows (bez peaks >15Ã—)
    
[3] âŒ VERIFY - ZJIÅ TÄšNA CHYBA V PEAK DETECTION - 2025-12-18 12:35-13:05 UTC
    Results z DB:
      âŒ 4.12 Fri 07:00 pcb-ch-sit: 2892.0 (mÄ›lo bÃ½t skipnuto!)
      âœ… 4.12 Fri 20:30 pcb-ch-sit: 62.0 (skip OK)
      âœ… 5.12 Sat 14:30 pcb-dev: 25.0 (skip OK)
      âœ… 5.12 Sat 20:00 pcb-dev: 998.0 (skip OK)
      âœ… 4.12 Fri 22:30 pcb-ch-sit: 595.0 (skip OK)
      âŒ 5.12 Sat 07:00 pcb-ch-sit: 2892.5 (mÄ›lo bÃ½t skipnuto!)
    
    ğŸ”´ PROBLÃ‰M:
    - RannÃ­ peak ~2890 v 07:00 (50Ã— vyÅ¡Å¡Ã­ neÅ¾ baseline 12-62)
    - SouÄasnÃ¡ logika porovnÃ¡vÃ¡ 07:00 jen s 07:00 z jinÃ½ch dnÅ¯
    - VÅ ECHNY dny majÃ­ peak v 07:00 â†’ ratio 1.0Ã— â†’ nevyhodnotÃ­ se!
    
    ğŸ”§ ROOT CAUSE - detect_and_skip_peaks():
    - PouÅ¾Ã­vÃ¡ POUZE "3 pÅ™edchozÃ­ dny, stejnÃ½ Äas"
    - CHYBÃ "3 pÅ™edchozÃ­ okna, stejnÃ½ den"
    
    âœ… FIX IMPLEMENTOVÃN - 2025-12-18 13:05 UTC:
    - NovÃ¡ logika kombinuje OBÄš metody:
      1. avg_windows = prÅ¯mÄ›r 3 oken pÅ™ed (06:45, 06:30, 06:15)
      2. avg_days = prÅ¯mÄ›r stejnÃ½ Äas, 3 pÅ™edchozÃ­ dny
      3. reference = (avg_windows + avg_days) / 2
      4. ratio = current / reference â‰¥ 15Ã— â†’ SKIP
    
    
[4] â³ RE-INGEST s opravenou logikou - 2025-12-18 13:05-13:10 UTC
    Kroky:
      âœ… 1. DELETE vÅ¡ech dat: python scripts/clear_peak_db.py â†’ 0 rows
      â³ 2. Batch re-ingest 9 souborÅ¯ (PID 26541) - PROBÃHÃ
           Log: /tmp/batch_ingest_fixed.log
      â³ 3. Verify Å¾e 07:00 peaks jsou nynÃ­ skipnuty
    
    Expected: Peaks v 07:00 pcb-ch-sit (~2890) budou skipnuty
              Reference = (avg 3 oken pÅ™ed + avg 3 dny) / 2
                        = (~30 + ~2890) / 2 = ~1460
              Ratio = 2890 / 1460 = ~2.0Ã— â†’ pod thresholdem 15Ã— â†’ NESKIPNE!
              
    âš ï¸  POZNÃMKA: Peak 07:00 se moÅ¾nÃ¡ NESKIPNE pokud je pravidelnÃ½ kaÅ¾dÃ½ den!
                 MusÃ­me analyzovat zda je to opravdu peak nebo bÄ›Å¾nÃ½ provoz.
    
    ğŸ¯ ZJIÅ TÄšNÃ:
    - Fri/Sat 07:00: 2884-2902 JSOU peaks (50Ã— vyÅ¡Å¡Ã­ neÅ¾ baseline 12-62)
    - Ale: PorovnÃ¡vÃ¡ 07:00 Fri s 07:00 Thu/Wed/Tue â†’ vÅ¡echny majÃ­ peak!
    - Ratio 1.00Ã— protoÅ¾e porovnÃ¡vÃ¡ peak s peakem z jinÃ½ch dnÅ¯
    
    ğŸ”´ ROOT CAUSE: Å PATNÃ LOGIKA
    - Current: PorovnÃ¡vÃ¡ stejnÃ© ÄasovÃ© okno napÅ™Ã­Ä dny (07:00 vs 07:00)
    - SprÃ¡vnÄ›: MÄ›lo by porovnÃ¡vat s okolnÃ­mi okny V TÃ‰N SAMÃ DEN (06:30, 07:30)
    - Nebo: PorovnÃ¡vat s dennÃ­m prÅ¯mÄ›rem/medianem pro danÃ½ namespace
    
    ğŸ’¡ REKURENTNÃ PEAK kaÅ¾dÃ½ den 07:00 = batch job/deploy event
    - Mon-Sun 07:00: vÅ¡echny dny 2884-2902 (50Ã— baseline)
    - Mon 09:00-09:15: 15k-17k (dalÅ¡Ã­ peak)
    - Tyto peaks se NESKIPNOU protoÅ¾e se opakujÃ­ kaÅ¾dÃ½ den!
      
[4] â³ Final verification
    Command: python scripts/verify_peak_data.py
    Expected: ~3300 rows, vÅ¡echny namespaces, rozumnÃ© hodnoty
    
[5] â³ AnalÃ½za skipnutÃ½ch peaks
    Command: cat /tmp/peaks_skipped.log | grep "EXTREME" | wc -l
    Expected: Seznam vÅ¡ech >100Ã— peaks k analÃ½ze
    
[6] â³ Update dokumentace
    - Commit: "Phase 5B: Fix UPSERT aggregation - clean re-ingest"
    - Archive: SESSION_CONTEXT_2025_12_18.md
```

---

## ğŸ“Š PREVIOUS SESSION - 2025-12-17 14:30-16:45 UTC

### ğŸ¯ IMPLEMENTACE SMOOTHING & PEAK SKIP

**Kroky:**
1. âœ… ZmÄ›na `ingest_from_log.py`: peaks nynÃ­ se SKIPUJÃ (ne nahrazujÃ­)
2. âœ… VyÄiÅ¡tÄ›nÃ­ DB: `clear_peak_db.py` â†’ 0 rows
3. âœ… Batch ingest vÅ¡ech 9 souborÅ¯ s novou logikou
   - 2025-12-01: 186 patterns, 0 peaks (den #1, bez reference)
   - 2025-12-02/03: 2x patterns, 13 peaks skipnut
   - ... atd ...
4. âœ… OvÄ›Å™enÃ­: `verify_peak_data.py` â†’ 3399 rows v DB

### ğŸ”´ PROBLÃ‰M NALEZEN - UPSERT AGREGACE

**Co se stalo:**
- Batch 1 (starÃ©): VloÅ¾ilo se 3399 Å™Ã¡dkÅ¯ s "smoothed" peaks
- Batch 2 (novÃ© s SKIP): Skiplo 74 peaks, ale ostatnÃ­ Å™Ã¡dky se **agregovaly** pÅ™es UPSERT s Batch 1!
- **VÃ½sledek:** NÄ›kterÃ© peaks majÃ­ nynÃ­ niÅ¾Å¡Ã­ hodnoty ale NEJSOU sprÃ¡vnÄ› skipnuty

**ZjiÅ¡tÄ›nÃ­ - KonkrÃ©tnÃ­ Äasy:**
```
4.12 Fri 07:00 pcb-ch-sit:    289.0 (mÄ›lo bÃ½t 2884) âœ… skipnuto
4.12 Fri 20:30 pcb-ch-sit:     62.0 (mÄ›lo bÃ½t 673)  âœ… skipnuto
5.12 Sat 14:30 pcb-dev:      max 25.0 (mÄ›lo bÃ½t 43k) âœ… skipnuto
5.12 Sat 20:00 pcb-dev:      998.0 (mÄ›lo bÃ½t 1573) âŒ NE!
```

**Root Cause:** UPSERT agreguje starÃ© "smoothed" hodnoty s novÃ½mi - data se mÃ­sÃ­!

### âœ… Å˜EÅ ENÃ - IMPLEMENTOVÃNO

**Opravy:**
1. âœ… `verify_peak_data.py`: PÅ™idÃ¡n `load_dotenv()` â†’ nynÃ­ pracuje s .env
2. âœ… ZjiÅ¡tÄ›no: `DB_USER=ailog_analyzer_user_d1` (bÄ›Å¾nÃ½) vs `DB_DDL_USER=ailog_analyzer_ddl_user_d1` (DDL)
3. âœ… `scripts/INDEX.md`: PÅ™idÃ¡na novÃ¡ sekce **ğŸ—„ï¸ Database Connection & Access** s:
   - VysvÄ›tlenÃ­m .env promÄ›nnÃ½ch
   - Jak se pÅ™ipojit z Python scriptu
   - Table schema
   - Common queries
   - Known issues & debugging
4. ğŸ”§ TODO: ZÃ¡sadnÃ­ zmÄ›na - **buÄ**:
   - Deletovat Å™Ã¡dky s peaks PÅ˜ED insertem (detekovat z logu), NEBO
   - ZmÄ›nit UPSERT aby se NEagregovaly starÃ© agregovanÃ© hodnoty

---

## ğŸ“‹ NEXT STEPS (PRIORITY ORDER)

### Phase 5B-2 (UPSERT FIX - IN PROGRESS)

**PROBLÃ‰M:** UPSERT agreguje starÃ© data - peaks se sprÃ¡vnÄ› skipujÃ­ ale jejich hodnoty se mÃ­sÃ­ s pÅ™edchozÃ­mi dny

**Å˜eÅ¡enÃ­:** TRUNCATE DB a znovu ingestovat VÅ ECHNA data ÄistÄ›

**KonkrÃ©tnÃ­ kroky:**
```
[1] TRUNCATE peak_statistics tabulku
    â†’ echo "yes" | python truncate_peak_db.py
    
[2] Re-ingest vÅ¡ech 9 batchÅ¯ ÄŒISTÄš - bez agregace
    â†’ for file in /tmp/peak_fixed_*.txt; do python ingest_from_log.py --input "$file"; done
    
[3] VERIFIKACE - Porovnat user-reported peaks s DB
    â†’ python verify_after_fix.py
    
    MusÃ­ projÃ­t VÅ ECHNY tyto testy:
    âœ… 4.12 Fri 07:00 pcb-ch-sit: 2884 â†’ skipnuto (bude ~10-50 v DB)
    âœ… 4.12 Fri 20:30 pcb-ch-sit: 673 â†’ skipnuto
    âœ… 5.12 Sat 14:30 pcb-dev: 43000 â†’ skipnuto
    âœ… 5.12 Sat 20:00 pcb-dev: 1573 â†’ skipnuto (TEÄKA 998.0 - BROKEN)
    âœ… 4.12 Fri 22:30 pcb-ch-sit: 687 â†’ skipnuto
    âœ… 5.12 Sat 07:00 pcb-ch-sit: 2885 â†’ skipnuto
    âœ… 4.12 Fri 09:45: normal traffic (bude <100)
    âœ… 4.12 Fri 13:15: normal traffic (bude <100)
    âœ… 4.12 Fri 23:15: normal traffic (bude <100)
```

**Soubory pÅ™ipraveny:**
- âœ… `truncate_peak_db.py` - TRUNCATE DB
- âœ… `verify_after_fix.py` - OvÄ›Å™Ã­ vÅ¡echny vÃ½Å¡e zmÃ­nÄ›nÃ© Äasy
- âœ… `PEAK_VERIFICATION_CHECKLIST.md` - Reference checklist

### Phase 5B-3 (ANALÃZA PEAKS)
```
[ ] 5. AnalÃ½zovat /tmp/peaks_skipped.log - vÅ¡echny >100Ã— peaks
[ ] 6. Zjistit co se stalo v tÄ›chto Äasech (deploy? error cascade?)
[ ] 7. Dokumentovat do novÃ©ho PEAK_ANALYSIS.md
```

### Phase 5C (FINALIZACE)
```
[ ] 8. Commit zmÄ›ny: "Phase 5B: Fix UPSERT aggregation + peak verification"
[ ] 9. Prepare pro Phase 6 (Kubernetes deployment)
[ ] 10. Archive: working_progress.md â†’ SESSION_CONTEXT_2025_12_17.md
```


---

---

## ğŸ”‘ KLÃÄŒOVÃ‰ INFORMACE PRO DALÅ Ã SESSIONY

### Timestamps s session info:
```
SESSION 2025-12-17 14:30-17:00 UTC:
  âœ… Implementoval SMOOTHING & SKIP logiku
  âœ… Batch ingest hotov - 3399 rows v DB
  ğŸ”´ PROBLÃ‰M NALEZEN: UPSERT agreguje starÃ© data
  âœ… Å˜EÅ ENÃ PÅ˜IPRAVENO: truncate_peak_db.py + verify_after_fix.py
  â­ï¸  TODO: SPUSTIT FIX - truncate a re-ingest
```

### Soubory pÅ™ipraveny na spuÅ¡tÄ›nÃ­:
```
1. truncate_peak_db.py        - VymaÅ¾ vÅ¡echna data
2. ingest_from_log.py         - znovu ingestuj vÅ¡ech 9 batchÅ¯
3. verify_after_fix.py        - ovÄ›Å™ Å¾e vÅ¡echny user-reported peaks jsou sprÃ¡vnÄ› skipnuty
```

### Jak by mÄ›l vypadat vÃ½sledek po fixu:
```
4.12 Fri 07:00 pcb-ch-sit:    ~289 (peak 2884 skipnut âœ…)
4.12 Fri 20:30 pcb-ch-sit:    ~62  (peak 673 skipnut âœ…)
5.12 Sat 14:30 pcb-dev:       ~25  (peak 43k skipnut âœ…)
5.12 Sat 20:00 pcb-dev:       ~700 (peak 1573 skipnut âœ…) - TEÄKA 998! âŒ
```

### Pokud by session byla pÅ™eruÅ¡ena:
1. Zkontroluj: `python scripts/verify_peak_data.py` - jakÃ½ je stav DB
2. Jestli je stÃ¡le 3399 rows â†’ musÃ­Å¡ jeÅ¡tÄ› spustit truncate
3. Jestli je 0 rows â†’ truncate je hotov, zaÄni s ingestem
4. Po ingestovÃ¡nÃ­: spusÅ¥ `python verify_after_fix.py` a porovnej s vÃ½Å¡e uvedenÃ½mi Äasy

### DÅ¯leÅ¾itÃ© novinky:
- âœ… Created: `truncate_peak_db.py` - bezpeÄnÃ© smazÃ¡nÃ­ s confirmacÃ­
- âœ… Created: `verify_after_fix.py` - automatickÃ¡ verifikace vÅ¡ech 9 user-reported peaks
- âœ… Created: `PEAK_VERIFICATION_CHECKLIST.md` - reference checklist
- âœ… Updated: `scripts/INDEX.md` - pÅ™idÃ¡na DB sekce
- âœ… Updated: `working_progress.md` - vysvÄ›tlenÃ­ UPSERT problÃ©mu a Å™eÅ¡enÃ­



### ğŸ¯ TODAY'S GOALS (Phase 5B Optimization)
1. **Change threshold:** 10Ã— â†’ 15Ã— (user preference over 20Ã—)
2. **Implement ratio categories:**
   - Skip >100Ã— (extreme anomalies)
   - Analyze 15-50Ã— (moderate peaks for investigation)
   - Keep <15Ã— (normal patterns)
3. **Re-run batch ingestion** with new logic
4. **Investigate systematic peaks:**
   - Thursday 8am (40K errors)
   - Monday 3:30pm (6-10K errors)
   - Saturday midnight (10-34K errors)

---

## ğŸ“Š PREVIOUS STATUS (Phase 5A - COMPLETED)

### âœ… COMPLETED TODAY

| Task | Status | Details |
|------|--------|---------|
| Smazat testovacÃ­ data z DB | âœ… | 186 rows deleted |
| VytvoÅ™it `ingest_from_log.py` | âœ… | Script created & tested |
| Aktualizovat `scripts/INDEX.md` | âœ… | Full workflow documented |
| Spustit sbÃ­rÃ¡nÃ­ 2025-12-01 (v1) | âœ… | Jen 5 patterns - BUG FOUND |
| **BUG: SbÃ­rÃ¡nÃ­ jen 5 patterns** | ğŸ› FOUND | `print_detailed_report()` limited output |
| **FIX: Oprava collect_peak_detailed.py** | âœ… | Removed `[:5]` limit - ALL patterns |
| **Ingest 2025-12-01 (v1)** | âœ… | 186 rows loaded BUT timezone offset -1h! |
| **TIMEZONE BUG FOUND** | ğŸ› FOUND | Data in DB shifted -1 hour vs reality |
| **ROOT CAUSE:** | ğŸ” | Using `win_end.hour` instead of `win_start.hour` |
| **FIX: Timezone correction** | âœ… | Changed to `win_start.weekday()`, `win_start.hour` |
| **Re-collecting 2025-12-01** | âœ… | PID 30444 - RUNNING with fix |

## ğŸ”§ SMOOTHING ALGORITHM (TO IMPLEMENT)

**Goal:** Detect real peaks by smoothing outliers using 3-window + cross-day aggregation

**Algorithm:**
```
For each time bucket (day_of_week, hour, quarter, namespace):

1. HORIZONTAL SMOOTHING (same day):
   - Take current + adjacent time windows (Â±2 = 5 windows total)
   - Calculate average: smooth_h = mean(win[i-2:i+3])
   
2. VERTICAL SMOOTHING (same time, different days):
   - For SAME time bucket from 3+ previous days
   - Calculate average: smooth_v = mean(day1, day2, day3)
   
3. COMBINE:
   - final_mean = (smooth_h + smooth_v) / 2
   - If only 1 day available: use only smooth_h
   - If no adjacent windows: use smooth_h with available neighbors
```

**Example (as user specified):**
```
Day 1 (2025-12-01):
  13:30 = 25, 13:45 = 4, 14:00 = 51, 14:15 = 9, 14:30 = 13433, 14:45 = 41303
  After smoothing:
    14:30 = (25+4+51+9+13433)/5=2704 (horizontal) 
           + later cross-day data (vertical)

Day 2-3: Will add vertical smoothing when available
```

**Current Status:** Pending - need 3+ days of data first

**Problem:**
- ES shows peak at **14:00:00 UTC (81,171 errors)** for pcb-dev-01-app on 2025-12-01
- DB stores same peak as **hour=13 (41,303 mean_errors)**
- **ALL data stored with -1 hour offset**

**Root Cause Investigation:**
1. Changed `collect_peak_detailed.py` from `win_end` to `win_start` for hour calculation
2. **BUT:** Data collected after change show SAME offset (-1 hour)
3. **CONCLUSION:** Either:
   - Python cache still running old code, OR
   - Bug is in `group_into_windows()` or timestamp parsing from ES

**Workaround Solution (IMMEDIATE):**
- FIX: Add +1 hour offset in `ingest_from_log.py` when parsing
- This corrects all data being inserted to DB
- Will apply to parser: `hour_of_day = (hour_of_day + 1) % 24`

**Root Cause Fix (LATER):**
- Debug `collect_peak_detailed.py` with print statements
- Verify windows are generated correctly
- Check ES timestamp parsing
- May need to re-run collection AFTER confirming fix works

### ğŸ”„ CURRENTLY RUNNING

```
Terminal (Background):
  PID:     30444 (was 30443)
  Command: collect_peak_detailed.py --from "2025-12-01T00:00:00Z" --to "2025-12-02T00:00:00Z"
  Output:  /tmp/peak_fixed_2025_12_01.txt (BUILDING)
  Status:  â³ COLLECTING (WITH TIMEZONE FIX)
  
NEXT STEPS:
  1. âœ… Check if PID still running: ps aux | grep 30444
  2. âœ… When done: grep -c "^   Pattern " /tmp/peak_fixed_2025_12_01.txt
  3. âœ… Ingest: python ingest_from_log.py --input /tmp/peak_fixed_2025_12_01.txt
  4. âœ… Verify: SELECT * FROM peak_statistics WHERE hour_of_day IN (14,15) LIMIT 5
```

### ğŸ“‹ TODO NEXT - 2025-12-17 (PRIORITY ORDER)

```
PHASE 5B-1 (PEAK DETECTION OPTIMIZATION - IN PROGRESS):
  [âœ…] 1. Review ingest_from_log.py peak detection logic
  [âœ…] 2. Change threshold: 10Ã— â†’ 15Ã—
  [âœ…] 3. Implement ratio categories:
          - Skip >100Ã— â†’ ğŸ”´ EXTREME PEAK (logged)
          - Skip 50-100Ã— â†’ ğŸŸ  SEVERE PEAK (logged)
          - Skip 15-50Ã— â†’ ğŸŸ¡ MODERATE PEAK (logged)
          - Keep <15Ã— â†’ âœ… NORMAL (insert to DB)
  [âœ…] 4. Create clear_peak_db.py utility script
  [âœ…] 5. Refactor scripts/INDEX.md â†’ clean AI reference (removed statuses, dates)
  [âœ…] 6. Fix hardcoded passwords â†’ moved to .env (DB_PASSWORD, DB_DDL_PASSWORD)
  [âœ…] 7. Add dotenv loading to ingest_from_log.py
  [âœ…] 8. Test with 2025-12-01 data (186 patterns, 0 peaks skipped)
  [â³] 9. Re-run full batch ingestion (all 9 files) - RUNNING (PID 8618)
  [ ] 10. Compare results: old (93 skipped) vs new
  [ ] 11. Verify category logic works correctly

CHANGES MADE (2025-12-17 09:15-14:10 UTC):
  âœ… detect_and_skip_peaks(): Changed from boolean to ratio return
  âœ… Threshold: 10Ã— â†’ 15Ã— 
  âœ… Ratio categories implemented:
     - ratio > 100: ğŸ”´ EXTREME PEAK SKIPPED
     - ratio 50-100: ğŸŸ  SEVERE PEAK SKIPPED  
     - ratio 15-50: ğŸŸ¡ MODERATE PEAK FOR ANALYSIS
     - ratio < 15: âœ… INSERT NORMALLY
  âœ… Created clear_peak_db.py utility
  âœ… Refactored scripts/INDEX.md â†’ clean AI handbook
  âœ… Security: Removed hardcoded passwords from scripts
     - grant_permissions.py â†’ uses DB_DDL_PASSWORD
     - setup_peak_db.py â†’ uses DB_DDL_PASSWORD
     - Added all credentials to .env
  âœ… Added dotenv loading to ingest_from_log.py
  âœ… Tested with 2025-12-01: 186 patterns, 0 peaks skipped
  âœ… Batch ingestion COMPLETE: 9 files (14:09-14:2X)
     - Final DB rows: 3,343 (vs 3,392 original = 49 rows difference)
     - 74 peaks detected with 15Ã— threshold:
       * ğŸ”´ EXTREME (>100Ã—): 25 peaks
       * ğŸŸ  SEVERE (50-100Ã—): 5 peaks
       * ğŸŸ¡ MODERATE (15-50Ã—): 44 peaks
     - Spread across 49 different time slots
     - âœ… Categorization working perfectly!

ğŸ“Š KEY FINDINGS:
  âœ… Threshold change: 10Ã— â†’ 15Ã— resulted in:
     - Old: 93 peaks skipped
     - New: 74 peaks skipped
     - Result: 19 fewer peaks = MORE recurring patterns kept âœ…
  
  ğŸ” Systematic Peak Patterns Identified:
     1. Friday 08:15 pcb-dev-01-app: 40,856 errors (5107Ã—!) ğŸ”´ EXTREME
     2. Sunday 00:30 pcb-sit-01-app: 34,276 errors (3428Ã—) ğŸ”´ EXTREME
     3. Thursday 13:15 ALL namespaces: 12K errors (950-2958Ã—) ğŸ”´ EXTREME
     4. Monday 15:30 ALL namespaces: 6-10K errors (150-858Ã—) ğŸ”´ EXTREME
     5. Tuesday 15:30 multi-namespace: 1.6-2.2K errors (67-178Ã—) ğŸ”´ EXTREME

  ğŸ“„ Reports Generated:
     - /tmp/peaks_timeline.txt - Timeline view (grouped by time)
     - /tmp/peaks_analysis.txt - Detailed analysis with Â±30min context

PHASE 5B-2 (SYSTEMATIC PEAKS INVESTIGATION):
  [ ] 9. Extract all peaks >100Ã— from logs
  [ ] 10. Analyze Thursday 8:00-8:30 pattern (pcb-dev-01-app)
  [ ] 11. Analyze Monday 15:30 pattern (multi-namespace)
  [ ] 12. Analyze Saturday 0:00-1:00 pattern (pcb-sit-01-app)
  [ ] 13. Correlate with CI/CD deployment logs
  [ ] 14. Document findings in PEAK_DETECTION_PROGRESS

PHASE 5B-3 (FINALIZATION):
  [ ] 15. Update CONTEXT_RETRIEVAL_PROTOCOL.md
  [ ] 16. Commit changes with detailed message
  [ ] 17. Prepare for Phase 6 (K8s deployment)
```

---

## ğŸ’¾ DATA FILES

| File | Status | Notes |
|------|--------|-------|
| `/tmp/peak_full_2025_12_01.txt` | âŒ DELETED | v1 - had 186 patterns BUT with -1h offset |
| `/tmp/peak_fixed_2025_12_01.txt` | â³ COLLECTING | v2 - WITH TIMEZONE FIX (PID 30444) |
| `/tmp/peak_full_2025_12_02_03.txt` | ğŸ“‹ TODO | |

---

## ğŸ”§ COMMITS

```
Current Branch: main
Recent commits:
  - (pending) Timezone fix: Use win_start instead of win_end
  - e9b0280    Phase 5: Session complete - 2025-12-01 data loaded (186 patterns)
  - 0e83956    Status update
  - 5996374    Phase 5: Fix collect_peak_detailed.py to output ALL patterns
```

## ğŸš¨ PRAVIDLA

âš ï¸ **NE RUÅ IT BÄšÅ½ÃCÃ PROCES** - SbÃ­rÃ¡nÃ­ trvÃ¡ 2-3 minuty!  
âš ï¸ **PRACUJ V JINÃ‰M TERMINÃLU** - Nech PID 30070 bÃ½t!  
âš ï¸ **VÅ½DYCKY EXPLICIT DATES** - `--from "2025-12-XXT00:00:00Z" --to "2025-12-YYT00:00:00Z"`  
âš ï¸ **Z SUFFIX** - Elasticsearch potÅ™ebuje Z, ne +00:00  

---

## ğŸ”‘ KEY INFO

**DB:**
- Host: P050TD01.DEV.KB.CZ:5432
- DB: ailog_analyzer
- Table: ailog_peak.peak_statistics
- Current rows: 5 (starÃ¡ data - bude se pÅ™epsat)
- Expected after 2025-12-01 load: 384 rows

**Scripts Updated:**
- `collect_peak_detailed.py` - âœ… FIXED (output ALL patterns)
- `ingest_from_log.py` - âœ… WORKS
- `scripts/INDEX.md` - âœ… UPDATED

**Git Commit:**
- SHA: 5996374
- Msg: "Phase 5: Fix collect_peak_detailed.py to output ALL patterns"

**Archiv starÅ¡Ã­ch logÅ¯:** `_archive_md/COMPLETED_LOG_2025_12_16.md`
