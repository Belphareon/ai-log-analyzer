# üîÑ Working Progress - AI Log Analyzer

**Projekt:** AI Log Analyzer - Trace-based Root Cause Analysis  
**Posledn√≠ aktualizace:** 2025-12-16 09:00 UTC  
**Status:** Phase 4 COMPLETE ‚úÖ - Phase 5 (Peak Detection Baseline) IN PROGRESS

---

## ‚ö†Ô∏è KRITICK√â - TIME RANGE HANDLING

### PAMATUJ SI V≈ΩDYCKY:
```
üö® TIMEZONE MUST BE UTC Z SUFFIX - NIKDY +00:00!
üö® ALWAYS USE EXPLICIT DATE RANGES - NIKDY datetime.now() RELATIVN√ç!
üö® CONTROL TIME RANGE BEFORE FETCHING - MUS√ç SOUHLASIT S EXPECTAC√ç!

CHYBN√â:
  start = (datetime.now(tz.utc) - timedelta(hours=24)).isoformat()
  ‚Üí Vr√°t√≠: 2025-12-15T08:52:41.537703+00:00  ‚ùå PLUS OFFSET
  
SPR√ÅVN√â:
  start = (datetime.now(tz.utc) - timedelta(hours=24)).isoformat().replace('+00:00', 'Z')
  ‚Üí Vr√°t√≠: 2025-12-15T08:52:41.537703Z  ‚úÖ WITH Z
  
NEJL√âPE:
  # Explicit ranges (SEMPRE!)
  --from "2025-12-15T00:00:00Z" --to "2025-12-16T00:00:00Z"

CHYBA KTER√Å SE STALA:
  - Stahoval jsem 88K errors (za 24h s p≈ôesahem)
  - Ty jsi vidƒõl 164K errors (za 24h)
  - Chybƒõlo mi 66.6K errors z peaku 2025-12-15T09:00-09:30
  - ROOT CAUSE: ƒåasov√Ω posun/OFF-BY-ONE v generov√°n√≠ windows
```

---

## üìö KNOWLEDGE BASE - Peak Detection Data Collection

### Database Configuration
```
Host: P050TD01.DEV.KB.CZ:5432
Database: ailog_analyzer
Schema: ailog_peak

DDL User (CREATE/ALTER):
  User: ailog_analyzer_ddl_user_d1
  Pass: WWvkHhyjje8YSgvU

Data User (INSERT/SELECT - POU≈Ω√çVAT V SCRIPTU):
  User: ailog_analyzer_user_d1
  Pass: y01d40Mmdys/lbDE
```

### Elasticsearch Configuration
```
URL: https://elasticsearch-test.kb.cz:9500
User: XX_PCBS_ES_READ
Pass: ta@@swLT69EX.6164

Index Pattern: cluster-app_pcb-*,cluster-app_pca-*,cluster-app_pcb-ch-*
```

### Peak Detection Script - UPDATED
```
Script: collect_peak_detailed.py
C√≠l: Sb√≠rat error counts v 15-minutov√Ωch oknech za N dn√≠

SPR√ÅVN√â POU≈ΩIT√ç:

Varianta 1: RELATIVN√ç (posledn√≠ N dn√≠ - VHODN√â POUZE PRO TESTING):
  python3 collect_peak_detailed.py --days 1
  python3 collect_peak_detailed.py --days 21

Varianta 2: EXPLICITN√ç (PREFEROVAN√â - MUS√ç B√ùT P≈òESN√â):
  python3 collect_peak_detailed.py --from "2025-12-15T00:00:00Z" --to "2025-12-16T00:00:00Z"
  python3 collect_peak_detailed.py --from "2025-11-25T00:00:00Z" --to "2025-12-15T23:59:59Z"

D≈ÆVOD:
- Relativn√≠ ƒçasy (--days) se poƒç√≠taj√≠ od datetime.now() ‚Üí VARIABILN√ç!
- Explicitn√≠ ƒçasy (--from/--to) jsou FIXN√ç ‚Üí OPAKOVATELN√â!
- Pro prod MUS√ç≈† V≈ΩDYCKY POU≈Ω√çVAT EXPLICITN√ç RANGE!
```

---

## üìä SESSION - 2025-12-16 08:15 UTC - Peak Detection Indexing Fix

### üéØ C√≠l
St√°hnout data za 48 hodin, ovƒõ≈ôit poƒçty errors a distribuci dle NS/app, vyƒçistit DB a spr√°vnƒõ ulo≈æit data se smoothingem.

### ‚úÖ Kroky Dokonƒçen√©

**1. Identifikace Probl√©mu (08:15-08:25 UTC)**
- Issue: `collect_peak_detailed.py` vr√°til 0 errors (mƒõlo vr√°tit 100K+)
- Root cause: Script pou≈æ√≠val ≈°patn√© env var `ES_INDICES` a ≈°patn√© indexy
  - Mƒõlo: `ES_INDEX` = `cluster-app_pcb-*,cluster-app_pca-*,cluster-app_pcb-ch-*`
  - Bylo: `ES_INDICES` = `logstash-kb-k8s-apps-nprod-*,logstash-kb-k8s-apps-prod-*`
- Bez pcb-ch dat!

**2. Secondary Issue - Timezone Format (08:25-08:30 UTC)**
- Script generoval `.isoformat()` ‚Üí `2025-12-14T09:15:00+00:00`
- ES oƒçek√°v√°: `2025-12-14T09:15:00Z`

**3. Oprava Scriptu (08:30 UTC)**
- `collect_peak_detailed.py` ES_CONFIG: Changed `ES_INDICES` ‚Üí `ES_INDEX` with correct indices
- `collect_peak_detailed.py` fetch_errors_search_after(): Added timezone fix
- Integration s `fetch_unlimited.py` - nyn√≠ pou≈æ√≠v√° proven working module

**4. Test & Verification (08:30-08:35 UTC)**
- ‚úÖ Quick test `--days 1`: 0 ‚Üí 10,000+ errors
- ‚úÖ Full run spu≈°tƒõn: `python3 collect_peak_detailed.py --days 2` (PID spu≈°tƒõn v /tmp/collect_pid.txt)
- ‚úÖ Namespace ovƒõ≈ôen√≠: fetch_unlimited vrac√≠ pcb-ch-dev-01-app + pcb-ch-sit-01-app

**5. Script Running (08:35+ UTC)**
- Background execution: `/tmp/collect_48h_final.log`
- Expected runtime: ~5-10 minut
- Process: Stahuje 120K+ errors ‚Üí groupuje ‚Üí poƒç√≠t√° stats s smoothingem

### üîß Zmƒõny v K√≥du

**File: `collect_peak_detailed.py`**
```python
# Line 21: FIX - Changed ES_INDICES to ES_INDEX
- 'indices': os.getenv('ES_INDICES', 'logstash-kb-k8s-apps-nprod-*,logstash-kb-k8s-apps-prod-*')
+ 'indices': os.getenv('ES_INDEX', 'cluster-app_pcb-*,cluster-app_pca-*,cluster-app_pcb-ch-*')

# Line 47-71: Integration s fetch_unlimited.py
- Nyn√≠ vol√° fetch_unlimited() m√≠sto vlastn√≠ implementace search_after
- To garantuje kompatibilitu s orchestrac√≠ (analyze_period.py)

# Line 49-50: FIX - Timezone format
date_from_str = date_from.isoformat().replace('+00:00', 'Z')
date_to_str = date_to.isoformat().replace('+00:00', 'Z')
```

### üìä DEBUG Output

```
‚úÖ Test za 1 hodinu (fetch_unlimited):
   Total errors: 740
   Namespaces: ['pca-dev-01-app', 'pca-sit-01-app', 
                'pcb-ch-dev-01-app', 'pcb-ch-sit-01-app',  ‚Üê NOVƒö!
                'pcb-dev-01-app', 'pcb-fat-01-app', 
                'pcb-sit-01-app', 'pcb-uat-01-app']

‚úÖ Collect za 48 hodin - COMPLETED (08:50 UTC):
   Total errors fetched: 120,261
   Grouped into: 844 (day,hour,quarter,ns) combinations
   
   üì¶ Namespaces found (8 TOTAL):
   - pca-dev-01-app              (44 patterns)
   - pca-sit-01-app              (46 patterns)
   - pcb-ch-dev-01-app           (52 patterns) ‚úÖ NOVƒö!
   - pcb-ch-sit-01-app           (104 patterns) ‚úÖ NOVƒö!
   - pcb-dev-01-app              (192 patterns)
   - pcb-fat-01-app              (144 patterns)
   - pcb-sit-01-app              (163 patterns)
   - pcb-uat-01-app              (145 patterns)
```

### ‚úÖ V√Ωsledek

**Status: FIX SUCCESSFUL! ‚úÖ**

Oprava ES_INDEX promƒõnn√© v `collect_peak_detailed.py` vy≈ôe≈°ila probl√©m. Script nyn√≠:
- Stahuje 120K+ errors spr√°vnƒõ
- Najde 8 namespace (vƒçetnƒõ pcb-ch-*)
- Poƒç√≠t√° mean/stddev s 3-window smoothingem

### üîó Reference

| Polo≈æka | Hodnota |
|---------|---------|
| Repo | `/home/jvsete/git/sas/ai-log-analyzer` |
| Database | P050TD01.DEV.KB.CZ:5432/ailog_analyzer |
| Elasticsearch | elasticsearch-test.kb.cz:9500 |
| Index Pattern | `cluster-app_pcb-*,cluster-app_pca-*,cluster-app_pcb-ch-*` |
| Env Var (CORRECT) | `ES_INDEX` |
| K8s Cluster | nprod (3095/3100) |

### Phase Status
- Phase 4: ‚úÖ COMPLETE
- Phase 5: üîÑ IN PROGRESS (collect_peak_detailed.py + fetch_unlimited integration)
- Phase 6: üìã TODO

---

## üìã NEXT SESSION TODO (2025-12-16+)

### ‚úÖ COMPLETED THIS SESSION
1. ‚úÖ Fixed ES_INDEX configuration (was ES_INDICES)
2. ‚úÖ Fixed timezone format (Z suffix)
3. ‚úÖ Integrated with fetch_unlimited.py
4. ‚úÖ Added explicit `--from` and `--to` date range support
5. ‚úÖ Verified 164,526 errors for 25h period (2025-12-15T00:00:00Z - 2025-12-16T01:00:00Z)
6. ‚úÖ All 8 namespaces confirmed (pcb-ch included!)

### üéØ NEXT STEPS (PRIORITY ORDER)

**STEP 1: Prepare Clean Data (with smoothing)**
```bash
# Run collection with EXPLICIT dates for 24h:
cd /home/jvsete/git/sas/ai-log-analyzer
source .venv/bin/activate

python3 collect_peak_detailed.py \
  --from "2025-12-15T00:00:00Z" \
  --to "2025-12-16T00:00:00Z" \
  --output /tmp/peak_data_24h.json

# Output will show:
# - Total errors count
# - 8 namespaces breakdown
# - Statistics (day,hour,quarter,namespace) with smoothing
# - Mean/StdDev values
```

**STEP 2: Export to Table Format (FOR VERIFICATION)**
```
Create CSV/Table with columns:
  - day_of_week (Mon-Sun)
  - hour_of_day (0-23)
  - quarter_hour (0/15/30/45)
  - namespace
  - mean_errors
  - stddev_errors
  - samples_count

THIS IS FOR YOUR VERIFICATION BEFORE DB LOAD!
```

**STEP 3: Clean Database (BEFORE LOAD)**
```sql
-- Connect as ailog_analyzer_user_d1
DELETE FROM ailog_peak.peak_statistics WHERE 1=1;
SELECT COUNT(*) FROM ailog_peak.peak_statistics;  -- Should be 0
```

**STEP 4: Load into Database**
```bash
# After your approval of Step 2 table:
# Script will INSERT all statistics into ailog_peak.peak_statistics
# Using UPSERT (ON CONFLICT) pattern
```

**STEP 5: Verify Smoothing Function**
```sql
-- Check smoothing values are reasonable
SELECT * FROM ailog_peak.peak_statistics 
WHERE namespace = 'pcb-sit-01-app' 
ORDER BY day_of_week, hour_of_day, quarter_hour
LIMIT 20;
```

### üìä Data Format Expected

```
Sample output from collect_peak_detailed.py:

day_of_week | hour_of_day | quarter_hour | namespace          | mean_errors | stddev_errors | samples
------------|-------------|--------------|-------------------|-------------|---------------|---------
0 (Mon)     | 8           | 0            | pcb-sit-01-app     | 203.32      | 45.67         | 3
0 (Mon)     | 8           | 15           | pcb-sit-01-app     | 195.45      | 42.15         | 3
0 (Mon)     | 8           | 30           | pcb-sit-01-app     | 187.23      | 40.89         | 3
...
```

### ‚ö†Ô∏è IMPORTANT REMINDERS
- ‚úÖ Use EXPLICIT dates (--from/--to), NOT --days for production
- ‚úÖ Always include 'Z' suffix in timestamps
- ‚úÖ Verify data count BEFORE deleting old DB
- ‚úÖ Create backup/screenshot of table BEFORE DB load
- ‚úÖ Check smoothing values make sense (not NaN, not negative)

---

**Ready for:** Next session - Execute Step 1-5 in order

---

## üìä SESSION - 2025-12-16 10:30 UTC - Workspace Cleanup & Phase 5 Setup

### üéØ C√≠l
Vyƒçistit workspace, archivovat star√© soubory, extrahovat d≈Øle≈æit√© info.

### ‚úÖ HOTOVO (10:30-11:00 UTC)

**1. Data Collection**
- ‚úÖ collect_peak_detailed.py: 2025-12-15 (163,847 errors)
- ‚úÖ collect_peak_detailed.py: 2025-12-01 (16 dn√≠ zp√°tky - CRITICAL)

**2. Scripts Cleanup**
- ‚úÖ 8 core scripts v root (keep)
- ‚úÖ 19 zastaral√Ωch skript≈Ø ‚Üí _archive_scripts/
- ‚úÖ 8 test_*.py skript≈Ø smaz√°no

**3. Documentation Cleanup**
- ‚úÖ README_SCRIPTS.md aktualizov√°n (8 core scripts)
- ‚úÖ CONTEXT_RETRIEVAL_PROTOCOL.md aktualizov√°n (Phase 5 status)
- ‚úÖ Vytv√°≈ôen√≠ PHASE_ROADMAP.md (Phase 5-7 planning)

**4. Data/Backup Archivace**
- ‚úÖ data/ ‚Üí /home/jvsete/git/sas/ai-data/
- ‚úÖ 11 zastaral√Ωch MD ‚Üí _archive_md/
- ‚úÖ export_peak_statistics.py vytvo≈ôen

**5. Workspace Reorganizace**
- ‚úÖ _archive_scripts/ (19 skript≈Ø)
- ‚úÖ _archive_md/ (11 dokument≈Ø)
- ‚úÖ Zb√Ωv√° 9 MD + 9 PY v root (clean!)

### üìä V√ùSLEDKY

| Item | P≈ôed | Po | Zmƒõna |
|------|------|----|----|
| Workspace | 618M | 404M | -214M |
| Root MD | 20+ | 9 | -11 (archivov√°no) |
| Root PY | 35 | 9 | -26 (archivov√°no) |
| Data soubory | 215M | v ai-data/ | archivov√°no |

**Aktivn√≠ v root:**
- Scripts: collect_peak_detailed.py, fetch_unlimited.py, analyze_period.py, + 5 DB scripts
- Docs: working_progress.md, CONTEXT_RETRIEVAL_PROTOCOL.md, HOW_TO_USE.md, README_SCRIPTS.md, + 4 others

### üîÑ NEXT PRIORITY (TODO)

**TODAY:**
- [ ] Vyƒçistit DB (DELETE star√© z peak_statistics)
- [ ] Nahr√°t nov√° data do DB
- [ ] Verifikovat integritu

**NEXT:**
- [ ] Vytvo≈ôit ingest_peak_statistics.py
- [ ] Phase 6a: DB schema validation
- [ ] Deploy to K8s

