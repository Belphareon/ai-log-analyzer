# ğŸ• AI Log Analyzer - K8s CronJob Scheduling
## Timing, Deployment Status, a Monitoring

---

## ğŸ“‹ CURRENT DEPLOYMENT STATUS (Feb 10, 2026)

### âœ… Configured & Ready
- **Two CronJobs** deployed in K8s manifests
- **Docker image**: r4 (174 MB) pushed to dockerhub.kb.cz
- **Teams integration**: ENABLED (TEAMS_ENABLED=true)
- **Confluence integration**: Ready (page 1334314207)

### ğŸš€ Next: `kubectl apply -f k8s-infra-apps-nprod/infra-apps/ai-log-analyzer/`

---

## ğŸ• CURRENT SCHEDULE

### 1ï¸âƒ£ **REGULAR PHASE** - KaÅ¾dÃ½ch 15 minut
```yaml
# CronJob: log-analyzer
schedule: "*/15 * * * *"  # 24/7,æ¯ 15 åˆ†é’Ÿ
command: python3 /app/scripts/regular_phase_v6.py
```

**Co dÄ›lÃ¡:**
- Zpracuje poslednÃ­ 15 minut dat z Elasticsearch
- Detekuje spikes/bursts/cross-namespace issues
- UklÃ¡dÃ¡ incidenty do PostgreSQL
- Updatuje registry (problÃ©my + peaks)
- POUZE na kritickÃ© problÃ©my â†’ Teams alert

**Expected output:**
```
âœ… Fetched X incidents from ES
âœ… Saved Y incidents to PostgreSQL
Registry updated: P problems, K peaks
[No Teams message unless critical]
```

---

### 2ï¸âƒ£ **BACKFILL PHASE** - Jednou dennÄ› rÃ¡no
```yaml
# CronJob: log-analyzer-backfill
schedule: "0 9 * * *"  # 09:00 UTC (11:00 CET Praha)
command: python3 /app/scripts/backfill_v6.py --days 1 --output /app/scripts/reports
```

**Co dÄ›lÃ¡:**
- Zpracuje VÄŒERAJÅ Ã DEN (kompletnÃ­ 24h data)
- Generuje podrobnÃ½ problem report (JSON, TXT, CSV)
- Publikuje do Confluence (page 1334314207)
- OdesÃ­lÃ¡ Teams notifikaci s EXECUTIVE SUMMARY
- Updatuje registry s novÃ½mi problÃ©my/peaks

**Expected output:**
```
âœ… Backfill processing started for N days
âœ… Total incidents fetched: X
âœ… Saved to PostgreSQL: Y
âœ… Problem reports generated:
   - problem_report_TIMESTAMP.txt
   - problem_report_TIMESTAMP.json
   - problem_report_TIMESTAMP.csv
âœ… Published to Confluence
âœ… Teams notification sent
```

**Teams message format:**
```
Log Analyzer run at 2026-02-10 09:15:32 UTC

Run Summary:
[TOP 3-5 Problems from EXECUTIVE SUMMARY]
- Problem 1: X occurrences
- Problem 2: Y severity
- ...
```

---

## ğŸ“Š FLOW DIAGRAM

```
Every 15 min (Regular Phase):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Regular Phase CronJob (*/15)    â”‚
â”‚ python3 regular_phase_v6.py     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â†’ Fetch last 15 min from ES
         â”œâ”€â†’ Pipeline: detect â†’ classify â†’ propagate
         â”œâ”€â†’ Save to PostgreSQL
         â”œâ”€â†’ Update registry
         â””â”€â†’ IF critical â†’ Teams alert

Daily at 09:00 UTC (Backfill Phase):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backfill CronJob (0 9 * * *)    â”‚
â”‚ python3 backfill_v6.py          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â†’ Fetch YESTERDAY'S data from ES
         â”œâ”€â†’ Pipeline: detect â†’ classify â†’ propagate
         â”œâ”€â†’ Save to PostgreSQL
         â”œâ”€â†’ Aggregate problems
         â”œâ”€â†’ Generate reports
         â”‚  â”œâ”€ problem_report_*.txt (human-readable)
         â”‚  â”œâ”€ problem_report_*.json (machine-readable)
         â”‚  â””â”€ errors/peaks CSVs
         â”‚
         â”œâ”€â†’ Publish to Confluence (API)
         â””â”€â†’ Send Teams notification (webhook)
```

---

## ğŸ“Š PUBLIKOVÃNÃ DO CONFLUENCE & TEAMS

### Backfill Output Files
```
/app/scripts/reports/
â”œâ”€â”€ problem_report_2026-02-10T091532.txt     â† Human-readable summary
â”œâ”€â”€ problem_report_2026-02-10T091532.json    â† Structured data
â”œâ”€â”€ problem_report_2026-02-10T091532.csv     â† Table format
â”œâ”€â”€ errors_table_latest.csv                  â† All errors
â””â”€â”€ peaks_table_latest.csv                   â† All peaks
```

### Confluence Updates
**Page:** 1334314207 (Recent Incidents - Problem Analysis)

**Content:** PROBLEM_ANALYSIS_REPORT V6
```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PROBLEM_ANALYSIS_REPORT V6
Backfill Analysis: 2026-02-09

EXECUTIVE SUMMARY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[Top 3-5 problems with occurrence count]

PROBLEM DETAILS (Top 20)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
For each problem:
  - ID: CATEGORY:flow:error_class
  - Count: X occurrences
  - First: timestamp
  - Last: timestamp
  - Services: [service1, service2, ...]
  - Sample: [sample error message]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Teams Integration
**Webhook:** `TEAMS_WEBHOOK_URL` from values.yaml
**Trigger:** At end of backfill (around 09:15 UTC)
**Message Format:**
```
Log Analyzer run at 2026-02-10 09:15:32 UTC

Run Summary:
BUSINESS:card_servicing:validation_error (245 occurrences)
DATABASE:batch_processing:connection_pool (128 occurrences)
AUTH:card_opening:access_denied (89 occurrences)
```

---

## âš™ï¸ CONFIGURATION (K8s values.yaml)

```yaml
# Image
app:
  image: dockerhub.kb.cz/pccm-sq016/ai-log-analyzer:r4
  imagePullPolicy: IfNotPresent

# Schedules are hardcoded in templates/cronjob.yaml
# Do NOT use {{ .Values.schedule }} - each job has own schedule

# Environment
env:
  DB_HOST: P050TD01.DEV.KB.CZ
  DB_NAME: ailog_analyzer
  ES_HOST: https://elasticsearch-test.kb.cz:9500
  REGISTRY_DIR: /data/registry
  EXPORT_DIR: /data/exports

# Teams & Confluence
teams:
  webhook_url: "https://sgcz.webhook.office.com/webhookb2/..."

# (TEAMS_ENABLED=true is set in cronjob.yaml)
# (CONFLUENCE_URL/PAGE_ID only used by backfill)
```

---

## ğŸ” MONITORING

### Check CronJob Status
```bash
kubectl get cronjobs -n ai-log-analyzer
kubectl get cronjob log-analyzer-backfill -n ai-log-analyzer -o wide
```

### Check Next Scheduled Run
```bash
kubectl get cronjob log-analyzer-backfill -n ai-log-analyzer \
  -o jsonpath='{.status.lastSuccessfulTime}'
```

### Monitor Logs
```bash
# Regular phase (last 15 min)
kubectl logs -n ai-log-analyzer -l job-type=regular --tail=50 -f

# Backfill (today's run)
kubectl logs -n ai-log-analyzer -l job-type=backfill --tail=200
```

### Verify Output
```bash
# Check if problem reports generated
kubectl exec -it POD_NAME -n ai-log-analyzer -- \
  ls -lah /app/scripts/reports/

# Check Confluence updated
curl -s https://confluence.kb.cz/pages/api/page/1334314207 \
  | grep -o "problem_report"

# Check Teams integration
# (Look at Teams channel for notifications)
```

---

## âš ï¸ TROUBLESHOOTING

### Backfill Not Running
```bash
# Check CronJob exists
kubectl describe cronjob log-analyzer-backfill -n ai-log-analyzer

# Check if pod created
kubectl get pods -n ai-log-analyzer --sort-by=.status.startTime

# Check pod logs
kubectl logs POD_NAME -n ai-log-analyzer
```

### Teams Notification Not Received
1. Verify webhook URL in values.yaml
2. Verify `TEAMS_ENABLED=true` in pod env:
   ```bash
   kubectl exec POD_NAME -n ai-log-analyzer -- \
     env | grep TEAMS
   ```
3. Check backfill logs for "Teams notification sent"

### Problem Reports Not Generated
1. Check `/app/scripts/reports/` directory exists
2. Verify output directory has write permissions
3. Check backfill logs for report generation step
4. Verify `--output /app/scripts/reports` argument in backfill command

### Confluence Not Updated
1. Verify page ID = 1334314207
2. Check Confluence credentials in pod
3. Verify `CONFLUENCE_URL=https://confluence.kb.cz`
4. Check logs for "Published to Confluence" message

---

## ğŸ“‹ MANUAL TESTING
Regular Phase (kaÅ¾dÃ½ch 15 minut)
    â†“
Detects critical issues?
    â”œâ”€ YES: Teams Alert (spike/burst/critical)
    â””â”€ NO: Silent (no alert)
    â†“
Exports CSV (updated)
    â†“
(Optional) Auto-publish to Confluence
```

---

## âš ï¸ FALLBACK STRATEGIE

Pokud se nÄ›co nezdaÅ™Ã­:

### **Backfill Failed**
```
âŒ DB write error / Elasticsearch error
â”œâ”€ Skript NEPROKRAÅ Ã (exit code â‰  0)
â”œâ”€ K8s zaznamenÃ¡dal failure (CronJob status: Failed)
â”œâ”€ Alert: "âš ï¸ Backfill failed on DATE"
â””â”€ Recovery: Manual re-run `run_backfill.sh --days 1`
```

### **Teams Notification Failed**
```
âš ï¸ Webhook is down / Network error
â”œâ”€ NEPROKRÃÅ UJE backfil (non-blocking)
â”œâ”€ Log: "âš ï¸ Teams notification failed: [error]"
â”œâ”€ Data jsou uloÅ¾ena v DB (je OK)
â””â”€ Recovery: Automatically sent next run (retry)
```

### **Confluence Upload Failed**
```
âš ï¸ API error / Invalid credentials
â”œâ”€ NEPROKRÃÅ UJE script (non-blocking)
â”œâ”€ Log: "âš ï¸ Failed to publish to Confluence: [error]"
â”œâ”€ CSV generovÃ¡n lokÃ¡lnÄ› (je OK)
â””â”€ Recovery: Manual `python confluence_publisher.py ...`
```

### **Regular Phase Failed**
```
âŒ Fetch error / Pipeline error
â”œâ”€ Skript ends with error (exit code â‰  0)
â”œâ”€ Next run za 15 minut (retry)
â”œâ”€ Alert: "âš ï¸ Regular phase failed"
â””â”€ Recovery: Automatic next run
```

---

## ğŸ”§ STRATEGIE PRO DLOUHODOBOU STABILITU

### 1. **Retry Logic**
```python
# V confluence_publisher.py a teams_notifier.py
for attempt in range(3):
    try:
        send_notification()
        break
    except Exception:
        if attempt < 2:
            time.sleep(5 * (attempt + 1))  # Exponential backoff
            continue
        raise
```

### 2. **Logging**
```bash
# VÅ¡echny cronjobdy logujÃ­ do:
# /var/log/ai-log-analyzer/backfill.log
# /var/log/ai-log-analyzer/regular.log
# /var/log/ai-log-analyzer/publish.log

# MÅ¯Å¾eÅ¡ vidÄ›t:
kubectl logs -n ai-log-analyzer job/ai-log-analyzer-backfill-<ID>
```

### 3. **Monitoring**
```yaml
# DoporuÄujeme Prometheus/Grafana metrics:
# - Backfill success/failure rate
# - Regular phase duration
# - Confluence publish status
# - DB write latency
```

### 4. **Alerting**
```yaml
# Teams Webhook Alert Conditions:
# - Backfill failed (3x fail in a row)
# - Regular phase stopped (no run for 30 min)
# - Confluence API unreachable
# - DB connection lost
```

---

## ğŸ“ ENVIRONMENT VARIABLES (v K8s)

```yaml
# .env nebo config/values.yaml
DB_HOST=P050TD01.DEV.KB.CZ
DB_PORT=5432
DB_USER=ailog_analyzer_user_d1
DB_DDL_USER=ailog_analyzer_ddl_user_d1
DB_PASSWORD=...
DB_DDL_PASSWORD=...
DB_DDL_ROLE=role_ailog_analyzer_ddl

ES_HOST=elasticsearch.kb.cz
ES_PORT=9200

TEAMS_WEBHOOK_URL=https://outlook.webhook.office.com/webhookb2/...
TEAMS_ENABLED=true

CONFLUENCE_URL=https://confluence.kb.cz
CONFLUENCE_USERNAME=XX_AWX_CONFLUENCE
CONFLUENCE_PASSWORD=PP_@9532bb-xmHV26
CONFLUENCE_DAILY_REPORT_PAGE_ID=1334314207
CONFLUENCE_KNOWN_ERRORS_PAGE_ID=1334314201
CONFLUENCE_KNOWN_PEAKS_PAGE_ID=1334314203
```

---

## ğŸš€ PÅ˜ÃKLAD K8S CRONJOB MANIFESTY

### Backfill CronJob:
```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: ai-log-analyzer-backfill
  namespace: ai-log-analyzer
spec:
  schedule: "0 9 * * *"  # 09:00 UTC
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backfill
            image: ai-log-analyzer:latest
            command:
            - /bin/sh
            - -c
            - cd /app && python3 scripts/backfill_v6.py --days 1 --output /app/scripts/reports
            env:
            - name: DB_HOST
              valueFrom:
                configMapKeyRef:
                  name: ai-log-analyzer-config
                  key: db-host
            # ... ostatnÃ­ env vars
            resources:
              requests:
                memory: "2Gi"
                cpu: "1000m"
              limits:
                memory: "4Gi"
                cpu: "2000m"
          restartPolicy: OnFailure
          backoffLimit: 3
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 5
```

### Regular Phase CronJob:
```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: ai-log-analyzer-regular
  namespace: ai-log-analyzer
spec:
  schedule: "*/15 * * * *"  # KaÅ¾dÃ½ch 15 minut
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: regular
            image: ai-log-analyzer:latest
            command:
            - /bin/sh
            - -c
            - cd /app && python3 scripts/regular_phase_v6.py
            env:
            # ... env vars
            resources:
              requests:
                memory: "1Gi"
                cpu: "500m"
              limits:
                memory: "2Gi"
                cpu: "1000m"
          restartPolicy: OnFailure
          backoffLimit: 2
  successfulJobsHistoryLimit: 5
  failedJobsHistoryLimit: 3
```

---

## ğŸ§ª TESTING SCHEDULE

NeÅ¾ to deployneÅ¡ do produkce:

```bash
# 1. Test backfill v suchÃ©m reÅ¾imu
python3 scripts/backfill_v6.py --days 1 --dry-run

# 2. Test regular phase
python3 scripts/regular_phase_v6.py --window 15 --dry-run

# 3. Test publishing
bash scripts/publish_daily_reports.sh --dry-run

# 4. Test Confluence connection
python3 scripts/confluence_publisher.py \
  --page-id 1334314201 \
  --csv-file ./scripts/exports/errors_table_latest.csv \
  --title "Test: Known Errors"

# 5. Test Teams notification
python3 -c "
from core.teams_notifier import TeamsNotifier
notifier = TeamsNotifier()
notifier.send_backfill_completed(
    days_processed=1,
    successful_days=1,
    failed_days=0,
    total_incidents=100,
    saved_count=100,
    registry_updates={'problems': 5, 'peaks': 1},
    duration_minutes=5.5
)
"
```

---

## âœ… CHECKLIST PRO DEPLOYMENT

- [ ] Backfill testovÃ¡n lokalnÄ› (1 den)
- [ ] Regular phase testovÃ¡n (15 min okno)
- [ ] Teams webhook ovÄ›Å™en (message pÅ™ijat)
- [ ] Confluence credentials ovÄ›Å™eny (CSV uploadovÃ¡n)
- [ ] K8s manifesty vytvoÅ™eny
- [ ] Resource limits nastaveny
- [ ] Logs nakonfigurÃ¡ny
- [ ] Monitoring/Alerting setup
- [ ] Backup strategie (registry YAML)
- [ ] Runbook pro failure scenarios

---

**VÃ­ce info:** [docs/PIPELINE_V4_ARCHITECTURE.md](./PIPELINE_V4_ARCHITECTURE.md)
