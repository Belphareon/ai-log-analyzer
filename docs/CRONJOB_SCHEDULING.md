# ğŸ• AI Log Analyzer - K8s CronJob Scheduling
## Timing, Deployment Status, a Monitoring

---

## ğŸ“‹ CURRENT DEPLOYMENT STATUS (Feb 10, 2026)

### âœ… Configured & Ready
- **Two CronJobs** deployed in K8s manifests
- **Docker image**: r4 (174 MB) pushed to dockerhub.kb.cz
- **Teams integration**: ENABLED (TEAMS_ENABLED=true)
- **Confluence integration**: Ready (page 1334314207)

### ğŸš€ Next: `kubectl apply -f k8s-infra-apps-nprod/infra-apps/ai-log-analyzer/`

---

## ğŸ• CURRENT SCHEDULE

### 1ï¸âƒ£ **REGULAR PHASE** - KaÅ¾dÃ½ch 15 minut
```yaml
# CronJob: log-analyzer
schedule: "*/15 * * * *"  # 24/7,æ¯ 15 åˆ†é’Ÿ
command: python3 /app/scripts/regular_phase.py
```

**Co dÄ›lÃ¡:**
- Zpracuje poslednÃ­ 15 minut dat z Elasticsearch
- PouÅ¾Ã­vÃ¡ PeakDetector (P93/CAP) pro spike detekci na Ãºrovni namespace
- Detekuje spikes/bursts/cross-namespace issues
- UklÃ¡dÃ¡ incidenty do PostgreSQL
- UklÃ¡dÃ¡ namespace totaly do `peak_raw_data` (pro budoucÃ­ P93 pÅ™epoÄet)
- Updatuje registry (problÃ©my + peaks)
- POUZE na kritickÃ© problÃ©my â†’ Teams alert

**Expected output:**
```
âœ… Fetched X incidents from ES
âœ… Saved Y incidents to PostgreSQL
Registry updated: P problems, K peaks
[No Teams message unless critical]
```

---

### 2ï¸âƒ£ **BACKFILL PHASE** - Jednou dennÄ› rÃ¡no
```yaml
# CronJob: log-analyzer-backfill
schedule: "0 9 * * *"  # 09:00 UTC (11:00 CET Praha)
command: python3 /app/scripts/backfill.py --days 1 --output /app/scripts/reports
```

**Co dÄ›lÃ¡:**
- Zpracuje VÄŒERAJÅ Ã DEN (kompletnÃ­ 24h data)
- PouÅ¾Ã­vÃ¡ PeakDetector (P93/CAP) pro spike detekci na Ãºrovni namespace
- Generuje podrobnÃ½ problem report (JSON, TXT, CSV)
- Publikuje do Confluence (page 1334314207)
- OdesÃ­lÃ¡ Teams notifikaci s EXECUTIVE SUMMARY
- Updatuje registry s novÃ½mi problÃ©my/peaks

**Expected output:**
```
âœ… Backfill processing started for N days
âœ… Total incidents fetched: X
âœ… Saved to PostgreSQL: Y
âœ… Problem reports generated:
   - problem_report_TIMESTAMP.txt
   - problem_report_TIMESTAMP.json
   - problem_report_TIMESTAMP.csv
âœ… Published to Confluence
âœ… Teams notification sent
```

---

### 3ï¸âƒ£ **THRESHOLD RECALCULATION** - TÃ½dnÄ› (doporuÄeno)
```bash
# RuÄnÃ­ nebo CronJob (doporuÄeno nedÄ›le v noci)
# schedule: "0 3 * * 0"  # 03:00 UTC nedÄ›le
python3 /app/scripts/core/calculate_peak_thresholds.py --weeks 4 --verbose
```

**Co dÄ›lÃ¡:**
- ÄŒte `peak_raw_data` za poslednÃ­ch N tÃ½dnÅ¯ (default: 4)
- PoÄÃ­tÃ¡ P93 percentil per (namespace, day_of_week)
- PoÄÃ­tÃ¡ CAP = (median_P93 + avg_P93) / 2 per namespace
- UklÃ¡dÃ¡ do `peak_thresholds` + `peak_threshold_caps`
- PeakDetector automaticky naÄte novÃ© thresholds (5-min cache)

**Konfigurace (env vars z values.yaml):**
- `PERCENTILE_LEVEL` - percentil (default: 0.93 = P93)
- `MIN_SAMPLES_FOR_THRESHOLD` - min vzorkÅ¯ pro spolehlivÃ½ threshold (default: 10)
- `DEFAULT_THRESHOLD` - fallback pokud chybÃ­ data (default: 100)

**Expected output:**
```
âœ… Loaded X raw data points from peak_raw_data
âœ… Calculated P93 thresholds for Y namespaces
âœ… Calculated CAP values for Y namespaces
âœ… Saved to peak_thresholds: Z rows
âœ… Saved to peak_threshold_caps: Y rows
```

**Teams message format:**
```
Log Analyzer run at 2026-02-10 09:15:32 UTC

Run Summary:
[TOP 3-5 Problems from EXECUTIVE SUMMARY]
- Problem 1: X occurrences
- Problem 2: Y severity
- ...
```

---

## ğŸ“Š FLOW DIAGRAM

```
Every 15 min (Regular Phase):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Regular Phase CronJob (*/15)    â”‚
â”‚ python3 regular_phase.py     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â†’ Fetch last 15 min from ES
         â”œâ”€â†’ Create PeakDetector (P93/CAP z DB)
         â”œâ”€â†’ Pipeline: detect (P93/CAP) â†’ classify â†’ propagate
         â”œâ”€â†’ Save to PostgreSQL
         â”œâ”€â†’ Save namespace totals to peak_raw_data â†â”€â”€ vstup pro P93 pÅ™epoÄet
         â”œâ”€â†’ Update registry
         â””â”€â†’ IF critical â†’ Teams alert

Daily at 09:00 UTC (Backfill Phase):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backfill CronJob (0 9 * * *)    â”‚
â”‚ python3 backfill.py          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â†’ Fetch YESTERDAY'S data from ES
         â”œâ”€â†’ Create PeakDetector (P93/CAP z DB)
         â”œâ”€â†’ Pipeline: detect (P93/CAP) â†’ classify â†’ propagate
         â”œâ”€â†’ Save to PostgreSQL
         â”œâ”€â†’ Aggregate problems
         â”œâ”€â†’ Generate reports
         â”‚  â”œâ”€ problem_report_*.txt (human-readable)
         â”‚  â”œâ”€ problem_report_*.json (machine-readable)
         â”‚  â””â”€ errors/peaks CSVs
         â”‚
         â”œâ”€â†’ Publish to Confluence (API)
         â””â”€â†’ Send Teams notification (webhook)

Weekly (Threshold Recalculation - doporuÄeno nedÄ›le):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ calculate_peak_thresholds.py --weeks 4       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â†’ Read peak_raw_data (poslednÃ­ch N tÃ½dnÅ¯)
         â”œâ”€â†’ Calculate P93 per (namespace, day_of_week)
         â”œâ”€â†’ Calculate CAP per namespace
         â””â”€â†’ Save to peak_thresholds + peak_threshold_caps
                  â†“
         PeakDetector automaticky naÄte (5-min cache)
```

**SamozdokonalovacÃ­ smyÄka:**
```
Regular Phase â†’ peak_raw_data roste â†’ calculate_peak_thresholds â†’ pÅ™esnÄ›jÅ¡Ã­ P93/CAP
     â†‘                                                                    â†“
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ PeakDetector naÄte novÃ© thresholds â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š PUBLIKOVÃNÃ DO CONFLUENCE & TEAMS

### Backfill Output Files
```
/app/scripts/reports/
â”œâ”€â”€ problem_report_2026-02-10T091532.txt     â† Human-readable summary
â”œâ”€â”€ problem_report_2026-02-10T091532.json    â† Structured data
â”œâ”€â”€ problem_report_2026-02-10T091532.csv     â† Table format
â”œâ”€â”€ errors_table_latest.csv                  â† All errors
â””â”€â”€ peaks_table_latest.csv                   â† All peaks
```

### Confluence Updates
**Page:** 1334314207 (Recent Incidents - Problem Analysis)

**Content:** PROBLEM_ANALYSIS_REPORT
```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PROBLEM_ANALYSIS_REPORT
Backfill Analysis: 2026-02-09

EXECUTIVE SUMMARY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[Top 3-5 problems with occurrence count]

PROBLEM DETAILS (Top 20)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
For each problem:
  - ID: CATEGORY:flow:error_class
  - Count: X occurrences
  - First: timestamp
  - Last: timestamp
  - Services: [service1, service2, ...]
  - Sample: [sample error message]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Teams Integration
**Webhook:** `TEAMS_WEBHOOK_URL` from values.yaml
**Trigger:** At end of backfill (around 09:15 UTC)
**Message Format:**
```
Log Analyzer run at 2026-02-10 09:15:32 UTC

Run Summary:
BUSINESS:card_servicing:validation_error (245 occurrences)
DATABASE:batch_processing:connection_pool (128 occurrences)
AUTH:card_opening:access_denied (89 occurrences)
```

---

## âš™ï¸ CONFIGURATION (K8s values.yaml)

```yaml
# Image
app:
  image: dockerhub.kb.cz/pccm-sq016/ai-log-analyzer:r36
  imagePullPolicy: IfNotPresent

# Schedules are hardcoded in templates/cronjob.yaml
# Do NOT use {{ .Values.schedule }} - each job has own schedule

# Environment
env:
  DB_HOST: P050TD01.DEV.KB.CZ
  DB_NAME: ailog_analyzer
  ES_HOST: https://elasticsearch-test.kb.cz:9500
  REGISTRY_DIR: /data/registry
  EXPORT_DIR: /data/exports

  # Peak Detection Algorithm (P93 OR CAP)
  PERCENTILE_LEVEL: "0.93"             # Percentil pro peak thresholds (P93 = 0.93)
  MIN_SAMPLES_FOR_THRESHOLD: "10"      # Min poÄet vzorkÅ¯ pro spolehlivÃ½ threshold
  DEFAULT_THRESHOLD: "100"             # Fallback threshold pokud chybÃ­ data v DB

  # InformativnÃ­ metriky (EWMA/MAD - NE pro spike detekci)
  EWMA_ALPHA: "0.3"                    # EWMA smoothing faktor pro trend metriky
  WINDOW_MINUTES: "15"                 # ÄŒasovÃ© okno pro analÃ½zu

# Teams & Confluence
teams:
  webhook_url: "https://sgcz.webhook.office.com/webhookb2/..."

# (TEAMS_ENABLED=true is set in cronjob.yaml)
# (CONFLUENCE_URL/PAGE_ID only used by backfill)
```

---

## ğŸ” MONITORING

### Check CronJob Status
```bash
kubectl get cronjobs -n ai-log-analyzer
kubectl get cronjob log-analyzer-backfill -n ai-log-analyzer -o wide
```

### Check Next Scheduled Run
```bash
kubectl get cronjob log-analyzer-backfill -n ai-log-analyzer \
  -o jsonpath='{.status.lastSuccessfulTime}'
```

### Monitor Logs
```bash
# Regular phase (last 15 min)
kubectl logs -n ai-log-analyzer -l job-type=regular --tail=50 -f

# Backfill (today's run)
kubectl logs -n ai-log-analyzer -l job-type=backfill --tail=200
```

### Verify Output
```bash
# Check if problem reports generated
kubectl exec -it POD_NAME -n ai-log-analyzer -- \
  ls -lah /app/scripts/reports/

# Check Confluence updated
curl -s https://confluence.kb.cz/pages/api/page/1334314207 \
  | grep -o "problem_report"

# Check Teams integration
# (Look at Teams channel for notifications)
```

---

## âš ï¸ TROUBLESHOOTING

### Backfill Not Running
```bash
# Check CronJob exists
kubectl describe cronjob log-analyzer-backfill -n ai-log-analyzer

# Check if pod created
kubectl get pods -n ai-log-analyzer --sort-by=.status.startTime

# Check pod logs
kubectl logs POD_NAME -n ai-log-analyzer
```

### Teams Notification Not Received
1. Verify webhook URL in values.yaml
2. Verify `TEAMS_ENABLED=true` in pod env:
   ```bash
   kubectl exec POD_NAME -n ai-log-analyzer -- \
     env | grep TEAMS
   ```
3. Check backfill logs for "Teams notification sent"

### Problem Reports Not Generated
1. Check `/app/scripts/reports/` directory exists
2. Verify output directory has write permissions
3. Check backfill logs for report generation step
4. Verify `--output /app/scripts/reports` argument in backfill command

### Confluence Not Updated
1. Verify page ID = 1334314207
2. Check Confluence credentials in pod
3. Verify `CONFLUENCE_URL=https://confluence.kb.cz`
4. Check logs for "Published to Confluence" message

---

## ğŸ“‹ MANUAL TESTING
Regular Phase (kaÅ¾dÃ½ch 15 minut)
    â†“
Detects critical issues?
    â”œâ”€ YES: Teams Alert (spike/burst/critical)
    â””â”€ NO: Silent (no alert)
    â†“
Exports CSV (updated)
    â†“
(Optional) Auto-publish to Confluence
```

---

## âš ï¸ FALLBACK STRATEGIE

Pokud se nÄ›co nezdaÅ™Ã­:

### **Backfill Failed**
```
âŒ DB write error / Elasticsearch error
â”œâ”€ Skript NEPROKRAÅ Ã (exit code â‰  0)
â”œâ”€ K8s zaznamenÃ¡dal failure (CronJob status: Failed)
â”œâ”€ Alert: "âš ï¸ Backfill failed on DATE"
â””â”€ Recovery: Manual re-run `run_backfill.sh --days 1`
```

### **Teams Notification Failed**
```
âš ï¸ Webhook is down / Network error
â”œâ”€ NEPROKRÃÅ UJE backfil (non-blocking)
â”œâ”€ Log: "âš ï¸ Teams notification failed: [error]"
â”œâ”€ Data jsou uloÅ¾ena v DB (je OK)
â””â”€ Recovery: Automatically sent next run (retry)
```

### **Confluence Upload Failed**
```
âš ï¸ API error / Invalid credentials
â”œâ”€ NEPROKRÃÅ UJE script (non-blocking)
â”œâ”€ Log: "âš ï¸ Failed to publish to Confluence: [error]"
â”œâ”€ CSV generovÃ¡n lokÃ¡lnÄ› (je OK)
â””â”€ Recovery: Manual `python confluence_publisher.py ...`
```

### **Regular Phase Failed**
```
âŒ Fetch error / Pipeline error
â”œâ”€ Skript ends with error (exit code â‰  0)
â”œâ”€ Next run za 15 minut (retry)
â”œâ”€ Alert: "âš ï¸ Regular phase failed"
â””â”€ Recovery: Automatic next run
```

---

## ğŸ”§ STRATEGIE PRO DLOUHODOBOU STABILITU

### 1. **Retry Logic**
```python
# V confluence_publisher.py a teams_notifier.py
for attempt in range(3):
    try:
        send_notification()
        break
    except Exception:
        if attempt < 2:
            time.sleep(5 * (attempt + 1))  # Exponential backoff
            continue
        raise
```

### 2. **Logging**
```bash
# VÅ¡echny cronjobdy logujÃ­ do:
# /var/log/ai-log-analyzer/backfill.log
# /var/log/ai-log-analyzer/regular.log
# /var/log/ai-log-analyzer/publish.log

# MÅ¯Å¾eÅ¡ vidÄ›t:
kubectl logs -n ai-log-analyzer job/ai-log-analyzer-backfill-<ID>
```

### 3. **Monitoring**
```yaml
# DoporuÄujeme Prometheus/Grafana metrics:
# - Backfill success/failure rate
# - Regular phase duration
# - Confluence publish status
# - DB write latency
```

### 4. **Alerting**
```yaml
# Teams Webhook Alert Conditions:
# - Backfill failed (3x fail in a row)
# - Regular phase stopped (no run for 30 min)
# - Confluence API unreachable
# - DB connection lost
```

---

## ğŸ“ ENVIRONMENT VARIABLES (v K8s)

```yaml
# Nastaveno v k8s/values.yaml -> injektovÃ¡no jako env vars pÅ™es cronjob.yaml

# === Database ===
DB_HOST=P050TD01.DEV.KB.CZ
DB_PORT=5432
DB_USER=ailog_analyzer_user_d1
DB_DDL_USER=ailog_analyzer_ddl_user_d1
DB_PASSWORD=...  # z Conjur/CyberArk
DB_DDL_PASSWORD=...  # z Conjur/CyberArk
DB_DDL_ROLE=role_ailog_analyzer_ddl

# === Elasticsearch ===
ES_HOST=https://elasticsearch-test.kb.cz:9500
ES_INDEX=cluster-app_pcb-*,cluster-app_pca-*,cluster-app_pcb_ch-*

# === Peak Detection (P93/CAP) ===
PERCENTILE_LEVEL=0.93              # Percentil pro peak thresholds
MIN_SAMPLES_FOR_THRESHOLD=10       # Min vzorkÅ¯ pro spolehlivÃ½ P93
DEFAULT_THRESHOLD=100              # Fallback pokud chybÃ­ data v DB

# === InformativnÃ­ metriky ===
EWMA_ALPHA=0.3                     # EWMA smoothing (jen trend metriky, NE spike detekce)
WINDOW_MINUTES=15                  # ÄŒasovÃ© okno pro analÃ½zu

# === Teams & Confluence ===
TEAMS_WEBHOOK_URL=https://sgcz.webhook.office.com/webhookb2/...
TEAMS_ENABLED=true

CONFLUENCE_URL=https://wiki.kb.cz
CONFLUENCE_PROXY=http://cntlm.speed-default:3128
CONFLUENCE_KNOWN_ERRORS_PAGE_ID=1334314201
CONFLUENCE_KNOWN_PEAKS_PAGE_ID=1334314203
```

---

## ğŸš€ PÅ˜ÃKLAD K8S CRONJOB MANIFESTY

### Backfill CronJob:
```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: ai-log-analyzer-backfill
  namespace: ai-log-analyzer
spec:
  schedule: "0 9 * * *"  # 09:00 UTC
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backfill
            image: ai-log-analyzer:latest
            command:
            - /bin/sh
            - -c
            - cd /app && python3 scripts/backfill.py --days 1 --output /app/scripts/reports
            env:
            - name: DB_HOST
              valueFrom:
                configMapKeyRef:
                  name: ai-log-analyzer-config
                  key: db-host
            # ... ostatnÃ­ env vars
            resources:
              requests:
                memory: "2Gi"
                cpu: "1000m"
              limits:
                memory: "4Gi"
                cpu: "2000m"
          restartPolicy: OnFailure
          backoffLimit: 3
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 5
```

### Regular Phase CronJob:
```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: ai-log-analyzer-regular
  namespace: ai-log-analyzer
spec:
  schedule: "*/15 * * * *"  # KaÅ¾dÃ½ch 15 minut
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: regular
            image: ai-log-analyzer:latest
            command:
            - /bin/sh
            - -c
            - cd /app && python3 scripts/regular_phase.py
            env:
            # ... env vars
            resources:
              requests:
                memory: "1Gi"
                cpu: "500m"
              limits:
                memory: "2Gi"
                cpu: "1000m"
          restartPolicy: OnFailure
          backoffLimit: 2
  successfulJobsHistoryLimit: 5
  failedJobsHistoryLimit: 3
```

---

## ğŸ§ª TESTING SCHEDULE

NeÅ¾ to deployneÅ¡ do produkce:

```bash
# 1. Test backfill v suchÃ©m reÅ¾imu
python3 scripts/backfill.py --days 1 --dry-run

# 2. Test regular phase
python3 scripts/regular_phase.py --window 15 --dry-run

# 3. Test P93/CAP thresholds
python3 scripts/core/calculate_peak_thresholds.py --dry-run --verbose

# 4. Zobrazit aktuÃ¡lnÃ­ thresholds
python3 scripts/core/peak_detection.py --show-thresholds

# 5. Test publishing
bash scripts/publish_daily_reports.sh --dry-run

# 6. Test Confluence connection
python3 scripts/confluence_publisher.py \
  --page-id 1334314201 \
  --csv-file ./scripts/exports/errors_table_latest.csv \
  --title "Test: Known Errors"

# 7. Test Teams notification
python3 -c "
from core.teams_notifier import TeamsNotifier
notifier = TeamsNotifier()
notifier.send_backfill_completed(
    days_processed=1,
    successful_days=1,
    failed_days=0,
    total_incidents=100,
    saved_count=100,
    registry_updates={'problems': 5, 'peaks': 1},
    duration_minutes=5.5
)
"
```

---

## âœ… CHECKLIST PRO DEPLOYMENT

- [ ] Backfill testovÃ¡n lokalnÄ› (1 den)
- [ ] Regular phase testovÃ¡n (15 min okno)
- [ ] P93/CAP thresholds naplnÄ›ny (`init_phase.py --days 21` + `calculate_peak_thresholds.py`)
- [ ] PeakDetector ovÄ›Å™en (`--show-thresholds` ukazuje data pro vÅ¡echny namespace)
- [ ] Teams webhook ovÄ›Å™en (message pÅ™ijat)
- [ ] Confluence credentials ovÄ›Å™eny (CSV uploadovÃ¡n)
- [ ] K8s manifesty vytvoÅ™eny
- [ ] Resource limits nastaveny
- [ ] Logs nakonfigurÃ¡ny
- [ ] Monitoring/Alerting setup
- [ ] Backup strategie (registry YAML)
- [ ] Runbook pro failure scenarios

---

**VÃ­ce info:** [docs/PIPELINE_ARCHITECTURE.md](./PIPELINE_ARCHITECTURE.md)
