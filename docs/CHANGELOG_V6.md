# AI Log Analyzer V6 - Opravy Registry a Detection

## PoslednÃ­ aktualizace (10. Ãºnora 2026)

### âœ… NovÃ© v tomto updatu

| Komponenta | ZmÄ›na | Commit |
|-----------|--------|--------|
| **PostgreSQL Transactions** | PÅ™idÃ¡n ROLLBACK exception handling | 5ad8904 |
| **Teams Notifications** | TEAMS_ENABLED env variable pro K8s | 8e1fbe4 |
| **K8s Deployment** | PÅ™idÃ¡n backfill CronJob (09:00 UTC) | bd5bad9 |
| **Docker Image** | Tag r4 s core/ a incident_analysis/ | local |
| **K8s Values** | Image tag r3â†’r4, vÅ¡echny env vars | bd5bad9 |

### ğŸ› OpravenÃ© bugy

| Bug | Root Cause | Å˜eÅ¡enÃ­ | Stav |
|-----|-----------|--------|------|
| Transaction abort cascade | ChybÃ­ ROLLBACK na exception | Added `conn.rollback()` | âœ… FIXED |
| Teams notifications silent | TEAMS_ENABLED not in K8s env | Added env variable | âœ… FIXED |
| PostgreSQL role permission | Expected behavior - user lacks grant | Documented as expected | âœ… HANDLED |

### ğŸš€ K8s Deployment Ready

- âœ… Two CronJobs deployed:
  - Regular Phase: `*/15 * * * *` (every 15 minutes)
  - Backfill Phase: `0 9 * * *` (09:00 UTC daily)
- âœ… Docker image r4 in registry (174 MB)
- âœ… All environment variables configured
- âœ… Teams notifications enabled
- âœ… Confluence integration ready (page 1334314207)

---

## PÅ™ehled problÃ©mÅ¯ a oprav

### âŒ PÅ¯vodnÃ­ problÃ©my

| # | ProblÃ©m | Dopad | Stav |
|---|---------|-------|------|
| 1a | Backfill opakovanÄ› uklÃ¡dÃ¡ data pro stejnÃ© dny | Duplicity v DB | âœ… FIXED |
| 1b | Registry lookup nefunguje - vÅ¡e je oznaÄeno jako NEW | 700k zÃ¡znamÅ¯ mÃ­sto ~1k | âœ… FIXED |
| 2 | `Root cause: Unknown` u vÄ›tÅ¡iny errorÅ¯ | Bez uÅ¾iteÄnÃ© klasifikace | âœ… IMPROVED |
| 3 | known_peaks.yaml prÃ¡zdnÃ© | Peaks se neuklÃ¡dajÃ­ | âœ… FIXED |
| 4 | ChybÃ­ detail k errorÅ¯m/peakÅ¯m | NedohledatelnÃ© | âœ… FIXED |
| 5 | Verze aplikace = "v1" (deployment label) | Å patnÃ¡ informace | âœ… FIXED |
| 6 | first_seen = last_seen | Timestamp bÄ›hu scriptu | âœ… FIXED |
| 7 | DuplicitnÃ­ fingerprinty | Exploze registry | âœ… FIXED |
| 8 | Script neukonÄÃ­ po report | VisÃ­ bez exitu | âœ… FIXED |

---

## NovÃ¡ architektura

### DvouÃºrovÅˆovÃ¡ identita problÃ©mÅ¯

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PROBLEM REGISTRY (LIDSKÃ)       â”‚  â† MÃ¡lo zÃ¡znamÅ¯, stabilnÃ­
â”‚ - problem_key                   â”‚
â”‚ - first_seen / last_seen        â”‚
â”‚ - occurrences                   â”‚
â”‚ - scope / flow                  â”‚
â”‚ - jira / notes                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ 1:N
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FINGERPRINT INDEX (TECHNICKÃ)   â”‚  â† HodnÄ› zÃ¡znamÅ¯
â”‚ - fingerprint                   â”‚
â”‚ - problem_key (FK)              â”‚
â”‚ - sample_messages               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Problem Key format

```
CATEGORY:flow:error_class

PÅ™Ã­klady:
- BUSINESS:card_servicing:validation_error
- DATABASE:batch_processing:connection_pool
- AUTH:card_opening:access_denied
```

---

## NovÃ© soubory

### Core moduly

| Soubor | Popis |
|--------|-------|
| `core/problem_registry.py` | HlavnÃ­ registry modul s problem_key |
| `pipeline/phase_c_detect.py` | Detection s registry integracÃ­ (V6) |

### Scripty

| Soubor | Popis |
|--------|-------|
| `backfill_v6.py` | Backfill s kompletnÃ­ registry integracÃ­ |
| `regular_phase_v6.py` | 15-min pipeline s registry |
| `migrate_registry.py` | Migrace starÃ©ho formÃ¡tu registry |

---

## Jak upgradovat

### Krok 1: Analyzuj stÃ¡vajÃ­cÃ­ registry

```bash
python migrate_registry.py --analyze --old-dir ./registry
```

VÃ½stup ukÃ¡Å¾e:
- PoÄet existujÃ­cÃ­ch zÃ¡znamÅ¯
- Distribuci kategoriÃ­
- Kolik problem_keys bude vytvoÅ™eno
- Detekci problematickÃ½ch timestampÅ¯

### Krok 2: SpusÅ¥ migraci (dry-run)

```bash
python migrate_registry.py --dry-run --old-dir ./registry
```

Preview bez zmÄ›n.

### Krok 3: SpusÅ¥ migraci

```bash
python migrate_registry.py --old-dir ./registry --new-dir ./registry
```

Automaticky vytvoÅ™Ã­ backup.

### Krok 4: PouÅ¾ij novÃ© scripty

```bash
# Backfill
python backfill_v6.py --days 14 --workers 4

# Regular phase (cron)
python regular_phase_v6.py
```

---

## KlÃ­ÄovÃ© zmÄ›ny v chovÃ¡nÃ­

### 1. Registry se naÄÃ­tÃ¡ pÅ™ed pipeline

**PÅ™edtÃ­m:**
```python
pipeline = PipelineV6()  # known_fingerprints = empty set
```

**NynÃ­:**
```python
registry = init_registry(registry_dir)
pipeline.phase_c.known_fingerprints = registry.get_all_known_fingerprints()
```

### 2. Event timestamps mÃ­sto run timestamps

**PÅ™edtÃ­m:**
```python
entry['first_seen'] = datetime.now().isoformat()  # âŒ ÄŒas scriptu
```

**NynÃ­:**
```python
entry.first_seen = min(entry.first_seen, incident.time.first_seen)  # âœ… ÄŒas eventu
```

### 3. Problem_key mÃ­sto 1:1 fingerprint

**PÅ™edtÃ­m:**
- KaÅ¾dÃ¡ varianta message = novÃ½ zÃ¡znam
- 700k zÃ¡znamÅ¯ po 20 dnech

**NynÃ­:**
- PodobnÃ© errory = jeden problem
- ~1k zÃ¡znamÅ¯ po 20 dnech

### 4. Peaks se uklÃ¡dajÃ­

**PÅ™edtÃ­m:**
```python
# Detekce spike=2 v logu
# known_peaks.md zÅ¯stÃ¡vÃ¡ prÃ¡zdnÃ©
```

**NynÃ­:**
```python
if incident.flags.is_spike:
    registry._update_peak(incident, 'SPIKE', first_ts, last_ts)
```

### 5. SprÃ¡vnÃ© ukonÄenÃ­ scriptu

**PÅ™edtÃ­m:**
- Script visÃ­ po "Report saved..."

**NynÃ­:**
```python
atexit.register(cleanup)
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)
```

---

## NovÃ½ formÃ¡t registry souborÅ¯

### known_problems.yaml

```yaml
- id: KP-000001
  problem_key: BUSINESS:card_servicing:validation_error
  category: business
  flow: card_servicing
  error_class: validation_error
  first_seen: '2026-01-05T08:15:32Z'  # Z event timestamps!
  last_seen: '2026-01-26T10:32:51Z'
  occurrences: 15432
  fingerprints:
    - a02e513ec5e3f683
    - 26478f5bf03fb6b6
    - 9882fe300e44ed0e
  affected_apps:
    - bff-pcb-ch-card-servicing-v1
    - bl-pcb-client-rainbow-status-v1
  affected_namespaces:
    - pcb-dev-01-app
    - pcb-sit-01-app
    - pcb-uat-01-app
  deployments_seen:
    - bff-pcb-ch-card-servicing-v1
  app_versions_seen:
    - 4.65.2
    - 4.65.3
  scope: CROSS_NS  # LOCAL | CROSS_NS | SYSTEMIC
  status: OPEN
  jira: null
  notes: null
```

### known_peaks.yaml

```yaml
- id: PK-000001
  problem_key: PEAK:business:card_servicing:spike
  peak_type: SPIKE
  first_seen: '2026-01-20T14:30:00Z'
  last_seen: '2026-01-25T09:15:00Z'
  occurrences: 12
  fingerprints:
    - a02e513ec5e3f683
  affected_apps:
    - bl-pcb-v1
  affected_namespaces:
    - pcb-sit-01-app
  max_value: 125.4
  max_ratio: 8.5
  status: OPEN
  jira: null
  notes: null
```

### fingerprint_index.yaml

```yaml
BUSINESS:card_servicing:validation_error:
  - a02e513ec5e3f683
  - 26478f5bf03fb6b6
  - 9882fe300e44ed0e
  
DATABASE:batch_processing:connection_pool:
  - f4a8e9b2c3d5a1b7
```

---

## DoporuÄenÃ½ deployment

### Kubernetes CronJob pro backfill

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: log-analyzer-backfill
spec:
  schedule: "0 2 * * 0"  # NedÄ›le 2:00
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: analyzer
            image: dockerhub.kb.cz/pccm-sq016/ai-log-analyzer:r1
            command:
            - python
            - backfill_v6.py
            - --days
            - "7"
            - --workers
            - "4"
          restartPolicy: OnFailure
```

### Kubernetes CronJob pro regular phase

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: log-analyzer-regular
spec:
  schedule: "*/15 * * * *"  # KaÅ¾dÃ½ch 15 minut
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: analyzer
            image: dockerhub.kb.cz/pccm-sq016/ai-log-analyzer:r1
            command:
            - python
            - regular_phase_v6.py
          restartPolicy: OnFailure
```

---

## TestovÃ¡nÃ­

### Dry-run backfill

```bash
python backfill_v6.py --days 3 --dry-run
```

OvÄ›Å™Ã­:
- Registry se naÄte
- Data se zpracujÃ­
- Nic se neuloÅ¾Ã­ do DB

### Forced re-processing

```bash
python backfill_v6.py --days 14 --force
```

Zpracuje i dny, kterÃ© uÅ¾ jsou v DB (pro regeneraci s novÃ½mi pravidly).

---

---

## V6.1 - Telemetry Context & Trace Propagation (2026-01-26)

### NovÃ© funkce

#### 1. IncidentTelemetryContext

JednotnÃ¡ normalizaÄnÃ­ vrstva pro ES eventy:

```python
@dataclass
class IncidentTelemetryContext:
    deployment_label: str                 # application.name (s -v1, -v2)
    application_version: Optional[str]    # POUZE X.Y.Z nebo None
    environment: Environment              # prod/uat/sit/dev
    trace_id: Optional[str]
    span_id: Optional[str]
    parent_span_id: Optional[str]
    event_timestamp: datetime
```

#### 2. Trace-based Propagation Detection

Detekce Å¡Ã­Å™enÃ­ incidentu pÅ™es vÃ­ce services pomocÃ­ traceId:

```python
# Agregace trace kontextÅ¯
trace_contexts = aggregate_trace_contexts(telemetry_contexts)

# Detekce propagace
propagation = detect_propagation(trace_contexts)

if propagation.propagated:
    print(f"Root service: {propagation.root_deployment}")
    print(f"Affected services: {propagation.affected_deployments}")
    print(f"Propagation time: {propagation.propagation_time_sec}s")
```

#### 3. OddÄ›lenÃ© verze a deploymenty

| Pole | Zdroj | PÅ™Ã­klad |
|------|-------|---------|
| `deployment_labels` | application.name | `my-app-v1`, `my-app-v2` |
| `app_versions` | application.version | `3.5.0`, `3.5.1` |

**ZAKÃZÃNO:**
- âŒ Extrakce verze z `-v1`, `-v2` suffixu
- âŒ Build number jako verze
- âŒ SDK/API version

#### 4. RozÅ¡Ã­Å™enÃ© tabulkovÃ© exporty

NovÃ© sloupce v CSV/MD/JSON exportech:

| Sloupec | Popis |
|---------|-------|
| `deployment_labels` | Deployment labels (app-v1, app-v2) |
| `app_versions` | SkuteÄnÃ© semantic verze (3.5.0) |

### NovÃ© soubory

| Soubor | Popis |
|--------|-------|
| `core/telemetry_context.py` | Telemetry normalizaÄnÃ­ vrstva |
| `exports/table_exporter.py` | TabulkovÃ© exporty (CSV, MD, JSON) |

### UpravenÃ© soubory

| Soubor | ZmÄ›ny |
|--------|-------|
| `pipeline/phase_a_parse.py` | Extrakce span_id, parent_span_id, environment |
| `pipeline/incident.py` | PropagationInfo, TraceInfo dataclasses |
| `core/problem_registry.py` | UklÃ¡dÃ¡nÃ­ app_versions_seen oddÄ›lenÄ› |

### PouÅ¾itÃ­

```bash
# Export tabulek
python exports/table_exporter.py --registry ../registry --output ./exports

# Backfill s novÃ½mi features
python backfill_v6.py --days 14 --workers 4
```

### CSV export ukÃ¡zka

```csv
problem_id,category,flow,deployment_labels,app_versions,scope,status
KP-000001,business,card,svc-a-v1,3.5.0,CROSS_NS,OPEN
```

---

## MoÅ¾nÃ¡ budoucÃ­ vylepÅ¡enÃ­

1. ~~**Verze aplikace** - Extrakce z ES pole `application.version`~~ âœ… DONE
2. ~~**Trace propagation** - Detekce Å¡Ã­Å™enÃ­ pÅ™es traceId~~ âœ… DONE
3. **XLSX export** - Pro lepÅ¡Ã­ prÃ¡ci s daty
4. **Flow detection** - AutomatickÃ¡ detekce business flows z call chain
5. **Trending** - Detekce trendÅ¯ napÅ™Ã­Ä dny

---

## Kontakt

PÅ™i problÃ©mech nebo dotazech kontaktuj tÃ½m SAS.
