"""Add analyzed_at column to findings

Revision ID: 1a266d9a61fb
Revises: ab4f703145e2
Create Date: 2025-11-07 14:11:20.106456

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '1a266d9a61fb'
down_revision = 'ab4f703145e2'
branch_labels = None
depends_on = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('analysis_history', sa.Column('fingerprint', sa.String(length=255), nullable=False))
    op.add_column('analysis_history', sa.Column('app_name', sa.String(length=100), nullable=False))
    op.add_column('analysis_history', sa.Column('namespace', sa.String(length=100), nullable=False))
    op.add_column('analysis_history', sa.Column('window_start', sa.DateTime(), nullable=False))
    op.add_column('analysis_history', sa.Column('window_end', sa.DateTime(), nullable=False))
    op.add_column('analysis_history', sa.Column('total_count', sa.Integer(), nullable=False))
    op.add_column('analysis_history', sa.Column('was_spike', sa.Integer(), nullable=False))
    op.add_column('analysis_history', sa.Column('ewma_at_time', sa.Float(), nullable=False))
    op.add_column('analysis_history', sa.Column('analyzed', sa.Integer(), nullable=False))
    op.add_column('analysis_history', sa.Column('analysis_confidence', sa.Float(), nullable=True))
    op.add_column('analysis_history', sa.Column('created_at', sa.DateTime(), nullable=False))
    op.drop_index(op.f('ix_analysis_history_timestamp'), table_name='analysis_history')
    op.create_index(op.f('ix_analysis_history_app_name'), 'analysis_history', ['app_name'], unique=False)
    op.create_index(op.f('ix_analysis_history_fingerprint'), 'analysis_history', ['fingerprint'], unique=False)
    op.create_index('ix_analysis_history_fp_window', 'analysis_history', ['fingerprint', 'window_start'], unique=False)
    op.create_index(op.f('ix_analysis_history_namespace'), 'analysis_history', ['namespace'], unique=False)
    op.create_index(op.f('ix_analysis_history_window_start'), 'analysis_history', ['window_start'], unique=False)
    op.drop_column('analysis_history', 'total_analyses')
    op.drop_column('analysis_history', 'top_errors')
    op.drop_column('analysis_history', 'critical_count')
    op.drop_column('analysis_history', 'timestamp')
    op.drop_column('analysis_history', 'top_apps')
    op.drop_column('analysis_history', 'ewma_baselines')
    op.drop_column('analysis_history', 'avg_confidence')
    op.drop_column('analysis_history', 'period_start')
    op.drop_column('analysis_history', 'high_count')
    op.drop_column('analysis_history', 'spike_findings')
    op.drop_column('analysis_history', 'total_findings')
    op.drop_column('analysis_history', 'count_history')
    op.drop_column('analysis_history', 'medium_count')
    op.drop_column('analysis_history', 'period_end')
    op.drop_column('analysis_history', 'low_count')
    op.drop_column('analysis_history', 'avg_analysis_time_ms')
    op.add_column('ewma_baselines', sa.Column('id', sa.Integer(), nullable=False))
    op.add_column('ewma_baselines', sa.Column('app_name', sa.String(length=100), nullable=False))
    op.add_column('ewma_baselines', sa.Column('namespace', sa.String(length=100), nullable=False))
    op.add_column('ewma_baselines', sa.Column('ewma_value', sa.Float(), nullable=False))
    op.add_column('ewma_baselines', sa.Column('ewma_alpha', sa.Float(), nullable=False))
    op.add_column('ewma_baselines', sa.Column('threshold_multiplier', sa.Float(), nullable=False))
    op.add_column('ewma_baselines', sa.Column('created_at', sa.DateTime(), nullable=False))
    op.add_column('ewma_baselines', sa.Column('updated_at', sa.DateTime(), nullable=False))
    op.alter_column('ewma_baselines', 'fingerprint',
               existing_type=sa.VARCHAR(length=64),
               type_=sa.String(length=255),
               existing_nullable=False)
    op.alter_column('ewma_baselines', 'count_history',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               nullable=False)
    op.alter_column('ewma_baselines', 'last_count',
               existing_type=sa.INTEGER(),
               nullable=False)
    op.alter_column('ewma_baselines', 'spike_count',
               existing_type=sa.INTEGER(),
               nullable=False)
    op.drop_index(op.f('ix_ewma_baselines_fingerprint'), table_name='ewma_baselines')
    op.create_index(op.f('ix_ewma_baselines_fingerprint'), 'ewma_baselines', ['fingerprint'], unique=True)
    op.create_index(op.f('ix_ewma_baselines_app_name'), 'ewma_baselines', ['app_name'], unique=False)
    op.create_index(op.f('ix_ewma_baselines_id'), 'ewma_baselines', ['id'], unique=False)
    op.create_index(op.f('ix_ewma_baselines_namespace'), 'ewma_baselines', ['namespace'], unique=False)
    op.drop_column('ewma_baselines', 'first_seen')
    op.drop_column('ewma_baselines', 'samples_count')
    op.drop_column('ewma_baselines', 'current_ewma')
    op.drop_column('ewma_baselines', 'alpha')
    op.drop_column('ewma_baselines', 'last_updated')
    op.drop_column('ewma_baselines', 'spike_threshold_multiplier')
    op.add_column('feedback', sa.Column('pattern_id', sa.Integer(), nullable=True))
    op.add_column('feedback', sa.Column('user_id', sa.String(length=100), nullable=True))
    op.add_column('feedback', sa.Column('created_at', sa.DateTime(), nullable=False))
    op.alter_column('feedback', 'pattern_updated',
               existing_type=sa.INTEGER(),
               nullable=False)
    op.drop_index(op.f('ix_feedback_submitted_at'), table_name='feedback')
    op.create_index(op.f('ix_feedback_created_at'), 'feedback', ['created_at'], unique=False)
    op.create_foreign_key(None, 'feedback', 'patterns', ['pattern_id'], ['id'])
    op.drop_column('feedback', 'submitted_at')
    op.drop_column('feedback', 'rating')
    op.drop_column('feedback', 'submitted_by')
    op.drop_column('feedback', 'threshold_adjusted')
    op.drop_column('feedback', 'correct_root_cause')
    op.drop_column('feedback', 'correct_severity')
    op.add_column('findings', sa.Column('analyzed_at', sa.DateTime(), nullable=True))
    op.add_column('findings', sa.Column('resolved_at', sa.DateTime(), nullable=True))
    op.alter_column('findings', 'fingerprint',
               existing_type=sa.VARCHAR(length=64),
               type_=sa.String(length=255),
               existing_nullable=False)
    op.alter_column('findings', 'app_name',
               existing_type=sa.VARCHAR(length=255),
               type_=sa.String(length=100),
               existing_nullable=False)
    op.alter_column('findings', 'namespace',
               existing_type=sa.VARCHAR(length=255),
               type_=sa.String(length=100),
               existing_nullable=False)
    op.alter_column('findings', 'container',
               existing_type=sa.VARCHAR(length=255),
               type_=sa.String(length=100),
               existing_nullable=True)
    op.alter_column('findings', 'normalized_message',
               existing_type=sa.TEXT(),
               nullable=False)
    op.alter_column('findings', 'level_value',
               existing_type=sa.INTEGER(),
               nullable=False)
    op.alter_column('findings', 'count',
               existing_type=sa.INTEGER(),
               nullable=False)
    op.alter_column('findings', 'first_seen',
               existing_type=postgresql.TIMESTAMP(),
               nullable=False)
    op.alter_column('findings', 'last_seen',
               existing_type=postgresql.TIMESTAMP(),
               nullable=False)
    op.alter_column('findings', 'resolved',
               existing_type=sa.BOOLEAN(),
               nullable=False)
    op.alter_column('findings', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               nullable=False)
    op.alter_column('findings', 'updated_at',
               existing_type=postgresql.TIMESTAMP(),
               nullable=False)
    op.drop_index(op.f('ix_findings_first_seen'), table_name='findings')
    op.drop_index(op.f('ix_findings_last_seen'), table_name='findings')
    op.drop_column('findings', 'feedback_comment')
    op.drop_column('findings', 'similar_incidents')
    op.drop_column('findings', 'feedback_timestamp')
    op.drop_column('findings', 'analysis_timestamp')
    op.drop_column('findings', 'resolution_notes')
    op.add_column('patterns', sa.Column('pattern_name', sa.String(length=200), nullable=False))
    op.add_column('patterns', sa.Column('pattern_type', sa.String(length=50), nullable=False))
    op.add_column('patterns', sa.Column('suggested_root_cause', sa.Text(), nullable=True))
    op.add_column('patterns', sa.Column('suggested_recommendations', sa.JSON(), nullable=True))
    op.add_column('patterns', sa.Column('true_positives', sa.Integer(), nullable=False))
    op.add_column('patterns', sa.Column('false_positives', sa.Integer(), nullable=False))
    op.add_column('patterns', sa.Column('active', sa.Boolean(), nullable=False))
    op.alter_column('patterns', 'auto_ignore',
               existing_type=sa.BOOLEAN(),
               nullable=False)
    op.alter_column('patterns', 'auto_action',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               type_=sa.String(length=50),
               existing_nullable=True)
    op.alter_column('patterns', 'occurrences',
               existing_type=sa.INTEGER(),
               nullable=False)
    op.alter_column('patterns', 'confidence',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               nullable=False)
    op.alter_column('patterns', 'created_by',
               existing_type=sa.VARCHAR(length=100),
               type_=sa.String(length=50),
               nullable=False)
    op.alter_column('patterns', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               nullable=False)
    op.alter_column('patterns', 'updated_at',
               existing_type=postgresql.TIMESTAMP(),
               nullable=False)
    op.drop_index(op.f('ix_patterns_pattern_hash'), table_name='patterns')
    op.create_index(op.f('ix_patterns_active'), 'patterns', ['active'], unique=False)
    op.create_index(op.f('ix_patterns_pattern_type'), 'patterns', ['pattern_type'], unique=False)
    op.create_unique_constraint(None, 'patterns', ['pattern_name'])
    op.drop_column('patterns', 'standard_recommendations')
    op.drop_column('patterns', 'severity')
    op.drop_column('patterns', 'root_cause_template')
    op.drop_column('patterns', 'description')
    op.drop_column('patterns', 'pattern_hash')
    op.drop_column('patterns', 'name')
    op.drop_column('patterns', 'category')
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('patterns', sa.Column('category', sa.VARCHAR(length=100), autoincrement=False, nullable=True))
    op.add_column('patterns', sa.Column('name', sa.VARCHAR(length=255), autoincrement=False, nullable=False))
    op.add_column('patterns', sa.Column('pattern_hash', sa.VARCHAR(length=64), autoincrement=False, nullable=False))
    op.add_column('patterns', sa.Column('description', sa.TEXT(), autoincrement=False, nullable=True))
    op.add_column('patterns', sa.Column('root_cause_template', sa.TEXT(), autoincrement=False, nullable=True))
    op.add_column('patterns', sa.Column('severity', sa.VARCHAR(length=20), autoincrement=False, nullable=True))
    op.add_column('patterns', sa.Column('standard_recommendations', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.drop_constraint(None, 'patterns', type_='unique')
    op.drop_index(op.f('ix_patterns_pattern_type'), table_name='patterns')
    op.drop_index(op.f('ix_patterns_active'), table_name='patterns')
    op.create_index(op.f('ix_patterns_pattern_hash'), 'patterns', ['pattern_hash'], unique=True)
    op.alter_column('patterns', 'updated_at',
               existing_type=postgresql.TIMESTAMP(),
               nullable=True)
    op.alter_column('patterns', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               nullable=True)
    op.alter_column('patterns', 'created_by',
               existing_type=sa.String(length=50),
               type_=sa.VARCHAR(length=100),
               nullable=True)
    op.alter_column('patterns', 'confidence',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               nullable=True)
    op.alter_column('patterns', 'occurrences',
               existing_type=sa.INTEGER(),
               nullable=True)
    op.alter_column('patterns', 'auto_action',
               existing_type=sa.String(length=50),
               type_=postgresql.JSON(astext_type=sa.Text()),
               existing_nullable=True)
    op.alter_column('patterns', 'auto_ignore',
               existing_type=sa.BOOLEAN(),
               nullable=True)
    op.drop_column('patterns', 'active')
    op.drop_column('patterns', 'false_positives')
    op.drop_column('patterns', 'true_positives')
    op.drop_column('patterns', 'suggested_recommendations')
    op.drop_column('patterns', 'suggested_root_cause')
    op.drop_column('patterns', 'pattern_type')
    op.drop_column('patterns', 'pattern_name')
    op.add_column('findings', sa.Column('resolution_notes', sa.TEXT(), autoincrement=False, nullable=True))
    op.add_column('findings', sa.Column('analysis_timestamp', postgresql.TIMESTAMP(), autoincrement=False, nullable=True))
    op.add_column('findings', sa.Column('feedback_timestamp', postgresql.TIMESTAMP(), autoincrement=False, nullable=True))
    op.add_column('findings', sa.Column('similar_incidents', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.add_column('findings', sa.Column('feedback_comment', sa.TEXT(), autoincrement=False, nullable=True))
    op.create_index(op.f('ix_findings_last_seen'), 'findings', ['last_seen'], unique=False)
    op.create_index(op.f('ix_findings_first_seen'), 'findings', ['first_seen'], unique=False)
    op.alter_column('findings', 'updated_at',
               existing_type=postgresql.TIMESTAMP(),
               nullable=True)
    op.alter_column('findings', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               nullable=True)
    op.alter_column('findings', 'resolved',
               existing_type=sa.BOOLEAN(),
               nullable=True)
    op.alter_column('findings', 'last_seen',
               existing_type=postgresql.TIMESTAMP(),
               nullable=True)
    op.alter_column('findings', 'first_seen',
               existing_type=postgresql.TIMESTAMP(),
               nullable=True)
    op.alter_column('findings', 'count',
               existing_type=sa.INTEGER(),
               nullable=True)
    op.alter_column('findings', 'level_value',
               existing_type=sa.INTEGER(),
               nullable=True)
    op.alter_column('findings', 'normalized_message',
               existing_type=sa.TEXT(),
               nullable=True)
    op.alter_column('findings', 'container',
               existing_type=sa.String(length=100),
               type_=sa.VARCHAR(length=255),
               existing_nullable=True)
    op.alter_column('findings', 'namespace',
               existing_type=sa.String(length=100),
               type_=sa.VARCHAR(length=255),
               existing_nullable=False)
    op.alter_column('findings', 'app_name',
               existing_type=sa.String(length=100),
               type_=sa.VARCHAR(length=255),
               existing_nullable=False)
    op.alter_column('findings', 'fingerprint',
               existing_type=sa.String(length=255),
               type_=sa.VARCHAR(length=64),
               existing_nullable=False)
    op.drop_column('findings', 'resolved_at')
    op.drop_column('findings', 'analyzed_at')
    op.add_column('feedback', sa.Column('correct_severity', sa.VARCHAR(length=20), autoincrement=False, nullable=True))
    op.add_column('feedback', sa.Column('correct_root_cause', sa.TEXT(), autoincrement=False, nullable=True))
    op.add_column('feedback', sa.Column('threshold_adjusted', sa.VARCHAR(length=100), autoincrement=False, nullable=True))
    op.add_column('feedback', sa.Column('submitted_by', sa.VARCHAR(length=100), autoincrement=False, nullable=True))
    op.add_column('feedback', sa.Column('rating', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('feedback', sa.Column('submitted_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True))
    op.drop_constraint(None, 'feedback', type_='foreignkey')
    op.drop_index(op.f('ix_feedback_created_at'), table_name='feedback')
    op.create_index(op.f('ix_feedback_submitted_at'), 'feedback', ['submitted_at'], unique=False)
    op.alter_column('feedback', 'pattern_updated',
               existing_type=sa.INTEGER(),
               nullable=True)
    op.drop_column('feedback', 'created_at')
    op.drop_column('feedback', 'user_id')
    op.drop_column('feedback', 'pattern_id')
    op.add_column('ewma_baselines', sa.Column('spike_threshold_multiplier', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('ewma_baselines', sa.Column('last_updated', postgresql.TIMESTAMP(), autoincrement=False, nullable=True))
    op.add_column('ewma_baselines', sa.Column('alpha', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('ewma_baselines', sa.Column('current_ewma', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False))
    op.add_column('ewma_baselines', sa.Column('samples_count', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('ewma_baselines', sa.Column('first_seen', postgresql.TIMESTAMP(), autoincrement=False, nullable=True))
    op.drop_index(op.f('ix_ewma_baselines_namespace'), table_name='ewma_baselines')
    op.drop_index(op.f('ix_ewma_baselines_id'), table_name='ewma_baselines')
    op.drop_index(op.f('ix_ewma_baselines_app_name'), table_name='ewma_baselines')
    op.drop_index(op.f('ix_ewma_baselines_fingerprint'), table_name='ewma_baselines')
    op.create_index(op.f('ix_ewma_baselines_fingerprint'), 'ewma_baselines', ['fingerprint'], unique=False)
    op.alter_column('ewma_baselines', 'spike_count',
               existing_type=sa.INTEGER(),
               nullable=True)
    op.alter_column('ewma_baselines', 'last_count',
               existing_type=sa.INTEGER(),
               nullable=True)
    op.alter_column('ewma_baselines', 'count_history',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               nullable=True)
    op.alter_column('ewma_baselines', 'fingerprint',
               existing_type=sa.String(length=255),
               type_=sa.VARCHAR(length=64),
               existing_nullable=False)
    op.drop_column('ewma_baselines', 'updated_at')
    op.drop_column('ewma_baselines', 'created_at')
    op.drop_column('ewma_baselines', 'threshold_multiplier')
    op.drop_column('ewma_baselines', 'ewma_alpha')
    op.drop_column('ewma_baselines', 'ewma_value')
    op.drop_column('ewma_baselines', 'namespace')
    op.drop_column('ewma_baselines', 'app_name')
    op.drop_column('ewma_baselines', 'id')
    op.add_column('analysis_history', sa.Column('avg_analysis_time_ms', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('analysis_history', sa.Column('low_count', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('analysis_history', sa.Column('period_end', postgresql.TIMESTAMP(), autoincrement=False, nullable=False))
    op.add_column('analysis_history', sa.Column('medium_count', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('analysis_history', sa.Column('count_history', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.add_column('analysis_history', sa.Column('total_findings', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('analysis_history', sa.Column('spike_findings', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.add_column('analysis_history', sa.Column('high_count', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('analysis_history', sa.Column('period_start', postgresql.TIMESTAMP(), autoincrement=False, nullable=False))
    op.add_column('analysis_history', sa.Column('avg_confidence', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('analysis_history', sa.Column('ewma_baselines', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.add_column('analysis_history', sa.Column('top_apps', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.add_column('analysis_history', sa.Column('timestamp', postgresql.TIMESTAMP(), autoincrement=False, nullable=False))
    op.add_column('analysis_history', sa.Column('critical_count', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('analysis_history', sa.Column('top_errors', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.add_column('analysis_history', sa.Column('total_analyses', sa.INTEGER(), autoincrement=False, nullable=True))
    op.drop_index(op.f('ix_analysis_history_window_start'), table_name='analysis_history')
    op.drop_index(op.f('ix_analysis_history_namespace'), table_name='analysis_history')
    op.drop_index('ix_analysis_history_fp_window', table_name='analysis_history')
    op.drop_index(op.f('ix_analysis_history_fingerprint'), table_name='analysis_history')
    op.drop_index(op.f('ix_analysis_history_app_name'), table_name='analysis_history')
    op.create_index(op.f('ix_analysis_history_timestamp'), 'analysis_history', ['timestamp'], unique=False)
    op.drop_column('analysis_history', 'created_at')
    op.drop_column('analysis_history', 'analysis_confidence')
    op.drop_column('analysis_history', 'analyzed')
    op.drop_column('analysis_history', 'ewma_at_time')
    op.drop_column('analysis_history', 'was_spike')
    op.drop_column('analysis_history', 'total_count')
    op.drop_column('analysis_history', 'window_end')
    op.drop_column('analysis_history', 'window_start')
    op.drop_column('analysis_history', 'namespace')
    op.drop_column('analysis_history', 'app_name')
    op.drop_column('analysis_history', 'fingerprint')
    # ### end Alembic commands ###
