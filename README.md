# AI Log Analyzer

Intelligent log analysis agent with self-learning capabilities for AWX logwatch integration.

## Features

- ğŸ¤– **Local LLM Analysis** - Uses Ollama (Mistral/Llama3) for intelligent log analysis
- ğŸ“Š **Pattern Recognition** - Automatically learns from historical findings
- ğŸ¯ **Self-Learning** - Adjusts thresholds and filters based on feedback
- ğŸ” **Context Enhancement** - Correlates with Elasticsearch, ArgoCD deployments
- ğŸ’¡ **Smart Recommendations** - Suggests root causes and remediation steps

## Architecture

```
AWX Logwatch â†’ AI Agent API â†’ Ollama LLM â†’ PostgreSQL
                    â†“
            Enhanced Findings + Insights
```

## Components

- **API Server** (FastAPI) - REST endpoints for AWX integration
- **Analyzer** - Core LLM-based log analysis
- **Learner** - Pattern recognition and auto-adjustment
- **Context Provider** - Elasticsearch and ArgoCD integration
- **Database** - PostgreSQL for findings history and learned patterns

## Tech Stack

- Python 3.11+
- FastAPI (async API)
- Ollama (local LLM)
- PostgreSQL (data persistence)
- SQLAlchemy (ORM)
- Kubernetes (deployment)

## Project Structure

```
ai-log-analyzer/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/              # FastAPI endpoints
â”‚   â”œâ”€â”€ core/             # Core analyzer logic
â”‚   â”œâ”€â”€ models/           # SQLAlchemy models
â”‚   â”œâ”€â”€ services/         # Business logic
â”‚   â”‚   â”œâ”€â”€ analyzer.py   # Main analysis engine
â”‚   â”‚   â”œâ”€â”€ learner.py    # Self-learning module
â”‚   â”‚   â”œâ”€â”€ llm.py        # Ollama client
â”‚   â”‚   â””â”€â”€ context.py    # ES/ArgoCD integration
â”‚   â”œâ”€â”€ schemas/          # Pydantic schemas
â”‚   â””â”€â”€ utils/            # Helpers
â”œâ”€â”€ k8s/                  # Kubernetes manifests
â”œâ”€â”€ tests/                # Unit tests
â”œâ”€â”€ docker-compose.yml    # Local development
â”œâ”€â”€ Dockerfile            # Container image
â”œâ”€â”€ pyproject.toml        # Poetry dependencies
â””â”€â”€ README.md
```

## Quick Start

### Local Development

```bash
# Install dependencies
poetry install

# Start services (PostgreSQL, Ollama)
docker-compose up -d

# Run migrations
poetry run alembic upgrade head

# Start API server
poetry run uvicorn app.main:app --reload
```

### API Usage

```bash
# Analyze findings
curl -X POST http://localhost:8000/api/v1/analyze \
  -H "Content-Type: application/json" \
  -d @findings.json

# Get learned patterns
curl http://localhost:8000/api/v1/patterns

# Submit feedback
curl -X POST http://localhost:8000/api/v1/feedback \
  -H "Content-Type: application/json" \
  -d '{"finding_id": "123", "is_valid": true}'
```

## Configuration

Environment variables:
- `DATABASE_URL` - PostgreSQL connection string
- `OLLAMA_URL` - Ollama API endpoint
- `OLLAMA_MODEL` - Model to use (mistral, llama3)
- `ES_URL` - Elasticsearch endpoint
- `ES_INDEX` - Log index pattern

## Development Roadmap

- [x] Project setup
- [ ] Core analyzer with Ollama
- [ ] PostgreSQL schema and models
- [ ] REST API endpoints
- [ ] Self-learning module
- [ ] Elasticsearch integration
- [ ] Kubernetes deployment
- [ ] AWX integration

## License

Internal KB use only
